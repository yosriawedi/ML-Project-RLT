{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# ğŸŒ² RLT Extra Trees: Ã‰tude Comparative ComplÃ¨te\n",
        "## Reinforcement Learning Trees - Analyse Multi-ModÃ¨les\n",
        "\n",
        "**Author:** Dhia Romdhane  \n",
        "**Date:** December 2025  \n",
        "**MÃ©thodologie:** CRISP-DM\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š Objectif\n",
        "\n",
        "Comparer **RLT-ExtraTrees** contre 7 autres modÃ¨les:\n",
        "\n",
        "1. **RLT-ExtraTrees** (Reinforcement Learning Trees)\n",
        "2. **RF** (Random Forest classique)\n",
        "3. **RF-âˆšp** (Random Forest avec mtry = âˆšp)\n",
        "4. **RF-log(p)** (Random Forest avec mtry = log(p))\n",
        "5. **ExtraTrees** (Extra Trees standard)\n",
        "6. **BART** (Bayesian Additive Regression Trees)\n",
        "7. **LASSO** (RÃ©gression LASSO)\n",
        "8. **Boosting** (XGBoost)\n",
        "\n",
        "### âš™ï¸ HyperparamÃ¨tres Fixes\n",
        "\n",
        "Tous les modÃ¨les utilisent les **mÃªmes configurations** pour comparaison Ã©quitable.\n",
        "\n",
        "### ğŸ“ Instructions\n",
        "\n",
        "1. ExÃ©cutez les cellules dans l'ordre (Shift+Enter)\n",
        "2. Uploadez votre dataset CSV quand demandÃ©\n",
        "3. Attendez les rÃ©sultats et visualisations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Installation des packages\n",
        "!pip install xgboost scikit-learn pandas numpy matplotlib seaborn scipy -q\n",
        "\n",
        "print('âœ… Toutes les bibliothÃ¨ques installÃ©es!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
        "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Lasso, LogisticRegression, LinearRegression\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Statistical tests\n",
        "from scipy.stats import f_oneway, pearsonr\n",
        "\n",
        "# File handling\n",
        "from google.colab import files\n",
        "import io\n",
        "import time\n",
        "\n",
        "# Random seed\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "print('âœ… BibliothÃ¨ques importÃ©es!')\n",
        "print(f'ğŸ“Œ Random State: {RANDOM_STATE}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell_4"
      },
      "outputs": [],
      "source": [
        "# Installation\n!pip install xgboost scikit-learn pandas numpy matplotlib seaborn scipy -q\n\nprint(\"âœ… BibliothÃ¨ques installÃ©es!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell_5"
      },
      "outputs": [],
      "source": [
        "# Data manipulation\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn-v0_8-darkgrid')\n\n# Machine Learning\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\nfrom sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.linear_model import Lasso, LogisticRegression, LinearRegression\nfrom xgboost import XGBClassifier, XGBRegressor\n\n# Metrics\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# Statistical tests\nfrom scipy.stats import f_oneway, pearsonr\n\n# File handling\nfrom google.colab import files\nimport io\nimport time\n\n# Random seed\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\nprint(\"âœ… BibliothÃ¨ques importÃ©es!\")\nprint(f\"ğŸ“Œ Random State: {RANDOM_STATE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell_6"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"âš™ï¸  CONFIGURATION DES HYPERPARAMÃˆTRES - FIXES POUR TOUS LES MODÃˆLES\")\nprint(\"=\"*70)\n\n# General settings\nRANDOM_STATE = 42\nTEST_SIZE = 0.2\nCV_FOLDS = 5\nN_JOBS = -1\n\n# RLT Configuration\nVI_THRESHOLD = 0.01\nVI_EXTRA_TREES_WEIGHT = 0.5\nVI_STAT_WEIGHT = 0.5\n\n# Tree-based models configuration (FIXED!)\nTREE_CONFIG = {\n    'n_estimators': 100,\n    'max_depth': None,\n    'min_samples_split': 2,\n    'min_samples_leaf': 1,\n    'random_state': RANDOM_STATE,\n    'n_jobs': N_JOBS\n}\n\n# XGBoost configuration (FIXED!)\nXGBOOST_CONFIG = {\n    'n_estimators': 100,\n    'max_depth': 6,\n    'learning_rate': 0.1,\n    'random_state': RANDOM_STATE,\n    'n_jobs': N_JOBS,\n    'verbosity': 0\n}\n\n# LASSO configuration (FIXED!)\nLASSO_CONFIG = {\n    'alpha': 0.1,\n    'random_state': RANDOM_STATE,\n    'max_iter': 1000\n}\n\n# Boosting configuration (FIXED!)\nBOOSTING_CONFIG = {\n    'n_estimators': 100,\n    'learning_rate': 0.1,\n    'random_state': RANDOM_STATE\n}\n\nprint(f\"\\\\nğŸ“Š ParamÃ¨tres GÃ©nÃ©raux:\")\nprint(f\"   - Random State: {RANDOM_STATE}\")\nprint(f\"   - Test Size: {TEST_SIZE}\")\nprint(f\"   - CV Folds: {CV_FOLDS}\")\nprint(f\"\\\\nğŸŒ² ParamÃ¨tres Tree-Based:\")\nprint(f\"   - n_estimators: {TREE_CONFIG['n_estimators']}\")\nprint(f\"   - max_depth: {TREE_CONFIG['max_depth']}\")\nprint(f\"\\\\nğŸ” ParamÃ¨tres RLT:\")\nprint(f\"   - VI Threshold: {VI_THRESHOLD}\")\nprint(f\"   - VI Extra Trees Weight: {VI_EXTRA_TREES_WEIGHT}\")\nprint(f\"   - VI Statistical Weight: {VI_STAT_WEIGHT}\")\nprint(\"\\\\nâœ… Configuration chargÃ©e!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell_7"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"ğŸ“ UPLOAD DE DATASET\")\nprint(\"=\"*70)\nprint(\"\\\\nğŸ‘‰ SÃ©lectionnez votre fichier CSV\")\nprint(\"   Format: CSV avec header, derniÃ¨re colonne = target\\\\n\")\n\nuploaded = files.upload()\n\n# Get filename\nfilename = list(uploaded.keys())[0]\nprint(f\"\\\\nâœ… Fichier uploadÃ©: {filename}\")\n\n# Load dataset\ndf = pd.read_csv(io.BytesIO(uploaded[filename]))\n\nprint(f\"\\\\nğŸ“Š Dataset chargÃ©:\")\nprint(f\"   - Shape: {df.shape}\")\nprint(f\"   - Samples: {df.shape[0]}\")\nprint(f\"   - Features: {df.shape[1] - 1}\")\nprint(f\"   - Target: {df.columns[-1]}\")\n\nprint(\"\\\\nğŸ“‹ AperÃ§u des donnÃ©es:\")\ndisplay(df.head())\n\nprint(\"\\\\nğŸ“ˆ Informations:\")\ndf.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell_8"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"ğŸ“Š CRISP-DM: DATA UNDERSTANDING\")\nprint(\"=\"*70)\n\n# Separate features and target\ntarget_col = df.columns[-1]\nfeatures = df.columns[:-1]\n\nprint(f\"\\\\nğŸ¯ Target: {target_col}\")\nprint(f\"ğŸ“Š Features ({len(features)}): {', '.join(features[:5])}{'...' if len(features) > 5 else ''}\")\n\n# Statistics\nprint(\"\\\\nğŸ“ˆ Statistiques des Features:\")\ndisplay(df[features].describe().T)\n\n# Target statistics\nprint(f\"\\\\nğŸ¯ Statistiques du Target '{target_col}':\")\nif df[target_col].dtype == 'object' or df[target_col].nunique() < 10:\n    print(\"   Type: Classification\")\n    print(f\"\\\\n   Distribution:\")\n    print(df[target_col].value_counts())\n    print(f\"\\\\n   Proportions:\")\n    print(df[target_col].value_counts(normalize=True))\nelse:\n    print(\"   Type: RÃ©gression\")\n    print(f\"\\\\n   Statistiques:\")\n    print(df[target_col].describe())\n\n# Missing values\nmissing = df.isnull().sum()\nmissing_pct = (missing / len(df)) * 100\nmissing_df = pd.DataFrame({\n    'Missing': missing,\n    'Percentage': missing_pct\n})\nmissing_df = missing_df[missing_df['Missing'] > 0].sort_values('Missing', ascending=False)\n\nprint(\"\\\\nâ“ Valeurs Manquantes:\")\nif len(missing_df) > 0:\n    print(f\"   âš ï¸  {len(missing_df)} colonnes avec valeurs manquantes\")\n    display(missing_df)\nelse:\n    print(\"   âœ… Aucune valeur manquante\")\n\n# Duplicates\nduplicates = df.duplicated().sum()\nprint(f\"\\\\nğŸ”„ Doublons:\")\nif duplicates > 0:\n    print(f\"   âš ï¸  {duplicates} lignes dupliquÃ©es ({duplicates/len(df)*100:.2f}%)\")\nelse:\n    print(f\"   âœ… Aucun doublon\")\n\n# Visualizations\nprint(\"\\\\nğŸ“Š GÃ©nÃ©ration des visualisations...\")\n\n# Target distribution\nplt.figure(figsize=(12, 5))\n\nif df[target_col].dtype == 'object' or df[target_col].nunique() < 10:\n    plt.subplot(1, 2, 1)\n    df[target_col].value_counts().plot(kind='bar', color='steelblue')\n    plt.title(f'Distribution de {target_col}', fontsize=14, fontweight='bold')\n    plt.xlabel(target_col)\n    plt.ylabel('Nombre')\n    plt.xticks(rotation=45)\n    \n    plt.subplot(1, 2, 2)\n    df[target_col].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=sns.color_palette('Set2'))\n    plt.title(f'Proportions de {target_col}', fontsize=14, fontweight='bold')\n    plt.ylabel('')\nelse:\n    plt.subplot(1, 2, 1)\n    plt.hist(df[target_col], bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n    plt.title(f'Distribution de {target_col}', fontsize=14, fontweight='bold')\n    plt.xlabel(target_col)\n    plt.ylabel('FrÃ©quence')\n    \n    plt.subplot(1, 2, 2)\n    plt.boxplot(df[target_col], vert=True)\n    plt.title(f'Box Plot de {target_col}', fontsize=14, fontweight='bold')\n    plt.ylabel(target_col)\n\nplt.tight_layout()\nplt.show()\n\n# Correlation matrix\nnumeric_df = df.select_dtypes(include=[np.number])\nif len(numeric_df.columns) > 1:\n    corr_matrix = numeric_df.corr()\n    \n    plt.figure(figsize=(12, 10))\n    sns.heatmap(corr_matrix, annot=len(numeric_df.columns) <= 15, fmt=\".2f\", \n                cmap='coolwarm', center=0, square=True, linewidths=1)\n    plt.title('Matrice de CorrÃ©lation', fontsize=16, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n    \n    if target_col in numeric_df.columns:\n        target_corr = corr_matrix[target_col].drop(target_col).sort_values(ascending=False)\n        print(f\"\\\\nğŸ¯ Top 10 CorrÃ©lations avec {target_col}:\")\n        print(target_corr.head(10))\n\nprint(\"\\\\nâœ… Data Understanding terminÃ©!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell_9"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"ğŸ”§ CRISP-DM: DATA PREPARATION\")\nprint(\"=\"*70)\n\n# 1. Detect problem type\ntarget_col = df.columns[-1]\nunique_values = df[target_col].nunique()\n\nif df[target_col].dtype == 'object' or unique_values < 10:\n    problem_type = 'classification'\n    print(f\"\\\\nâœ… Type: CLASSIFICATION\")\n    print(f\"   - Target: {target_col}\")\n    print(f\"   - Classes: {unique_values}\")\nelse:\n    problem_type = 'regression'\n    print(f\"\\\\nâœ… Type: RÃ‰GRESSION\")\n    print(f\"   - Target: {target_col}\")\n    print(f\"   - Range: [{df[target_col].min():.2f}, {df[target_col].max():.2f}]\")\n\n# 2. Clean data\ndf_clean = df.copy()\ninitial_shape = df_clean.shape\n\n# Remove duplicates\ndf_clean = df_clean.drop_duplicates()\nprint(f\"\\\\nğŸ§¹ Doublons supprimÃ©s: {initial_shape[0] - df_clean.shape[0]}\")\n\n# Handle missing values\nnumeric_cols = df_clean.select_dtypes(include=[np.number]).columns\nfor col in numeric_cols:\n    if df_clean[col].isnull().sum() > 0:\n        df_clean[col].fillna(df_clean[col].median(), inplace=True)\n\ncategorical_cols = df_clean.select_dtypes(include=['object']).columns\nfor col in categorical_cols:\n    if df_clean[col].isnull().sum() > 0:\n        df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n\n# 3. Separate features and target\nX = df_clean.iloc[:, :-1]\ny = df_clean.iloc[:, -1]\n\n# 4. Encode categorical features\ncategorical_features = X.select_dtypes(include=['object']).columns\nif len(categorical_features) > 0:\n    print(f\"\\\\nğŸ”„ Encoding {len(categorical_features)} categorical features...\")\n    X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\nelse:\n    X_encoded = X.copy()\n\n# 5. Encode target if classification\nif problem_type == 'classification':\n    if y.dtype == 'object':\n        le = LabelEncoder()\n        y_encoded = le.fit_transform(y)\n        print(f\"\\\\nğŸ¯ Target encodÃ©: {le.classes_}\")\n    else:\n        y_encoded = y.values\nelse:\n    y_encoded = y.values\n\n# 6. Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_encoded)\nX_scaled = pd.DataFrame(X_scaled, columns=X_encoded.columns)\n\nprint(f\"\\\\nğŸ“ Features scaled (StandardScaler)\")\nprint(f\"   - Shape: {X_scaled.shape}\")\nprint(f\"   - Features: {X_scaled.shape[1]}\")\n\n# 7. Split train/test\nif problem_type == 'classification':\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_scaled, y_encoded, \n        test_size=TEST_SIZE, \n        random_state=RANDOM_STATE,\n        stratify=y_encoded\n    )\nelse:\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_scaled, y_encoded, \n        test_size=TEST_SIZE, \n        random_state=RANDOM_STATE\n    )\n\nprint(f\"\\\\nâœ‚ï¸  Split Train/Test:\")\nprint(f\"   - Train: {X_train.shape[0]} samples ({(1-TEST_SIZE)*100:.0f}%)\")\nprint(f\"   - Test: {X_test.shape[0]} samples ({TEST_SIZE*100:.0f}%)\")\nprint(f\"   - Features: {X_train.shape[1]}\")\n\nprint(\"\\\\nâœ… Data Preparation terminÃ©!\")\nprint(\"ğŸ¯ DonnÃ©es prÃªtes pour la modÃ©lisation!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell_10"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"ğŸ§  RLT: VARIABLE IMPORTANCE\")\nprint(\"=\"*70)\n\ndef compute_rlt_variable_importance(X, y, problem_type):\n    \"\"\"\n    Compute Variable Importance using Extra Trees + Statistical tests\n    \"\"\"\n    print(\"\\\\nğŸ“Š Calcul de Variable Importance...\")\n    \n    # 1. Extra Trees VI\n    if problem_type == 'classification':\n        et = ExtraTreesClassifier(**TREE_CONFIG)\n    else:\n        et = ExtraTreesRegressor(**TREE_CONFIG)\n    \n    et.fit(X, y)\n    vi_et = et.feature_importances_\n    print(f\"   âœ… Extra Trees VI calculÃ©\")\n    \n    # 2. Statistical VI\n    vi_stat = np.zeros(X.shape[1])\n    for i, col in enumerate(X.columns):\n        try:\n            if problem_type == 'classification':\n                groups = [X[col][y == label] for label in np.unique(y)]\n                f_stat, _ = f_oneway(*groups)\n                vi_stat[i] = f_stat / 1000.0\n            else:\n                corr, _ = pearsonr(X[col], y)\n                vi_stat[i] = abs(corr)\n        except:\n            vi_stat[i] = 0\n    \n    print(f\"   âœ… Statistical VI calculÃ©\")\n    \n    # 3. Normalize\n    vi_et = vi_et / vi_et.sum() if vi_et.sum() > 0 else vi_et\n    vi_stat = vi_stat / vi_stat.sum() if vi_stat.sum() > 0 else vi_stat\n    \n    # 4. Aggregate\n    vi_aggregate = VI_EXTRA_TREES_WEIGHT * vi_et + VI_STAT_WEIGHT * vi_stat\n    \n    # 5. Create DataFrame\n    vi_df = pd.DataFrame({\n        'Feature': X.columns,\n        'VI_ExtraTrees': vi_et,\n        'VI_Statistical': vi_stat,\n        'VI_Aggregate': vi_aggregate\n    }).sort_values('VI_Aggregate', ascending=False)\n    \n    return vi_df\n\n# Compute VI\nvi_scores = compute_rlt_variable_importance(X_train, y_train, problem_type)\n\nprint(f\"\\\\nğŸ” Top 15 Features par VI:\")\ndisplay(vi_scores.head(15))\n\n# Plot VI\nplt.figure(figsize=(12, 6))\ntop_features = vi_scores.head(20)\nplt.barh(range(len(top_features)), top_features['VI_Aggregate'], color='steelblue')\nplt.yticks(range(len(top_features)), top_features['Feature'])\nplt.xlabel('Variable Importance')\nplt.title('Top 20 Features par Variable Importance', fontsize=14, fontweight='bold')\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.show()\n\n# Apply muting\nhigh_vi_features = vi_scores[vi_scores['VI_Aggregate'] >= VI_THRESHOLD]['Feature'].tolist()\nlow_vi_features = vi_scores[vi_scores['VI_Aggregate'] < VI_THRESHOLD]['Feature'].tolist()\n\n# Ensure minimum features\nif len(high_vi_features) < 5:\n    high_vi_features = vi_scores.head(5)['Feature'].tolist()\n    low_vi_features = vi_scores.iloc[5:]['Feature'].tolist()\n\n# Create muted datasets\nX_train_muted = X_train[high_vi_features]\nX_test_muted = X_test[high_vi_features]\n\nprint(f\"\\\\nğŸ”‡ Variable Muting:\")\nprint(f\"   - Original features: {X_train.shape[1]}\")\nprint(f\"   - Features mutÃ©es: {len(low_vi_features)} ({len(low_vi_features)/X_train.shape[1]*100:.1f}%)\")\nprint(f\"   - Features gardÃ©es: {len(high_vi_features)} ({len(high_vi_features)/X_train.shape[1]*100:.1f}%)\")\nprint(f\"   - Seuil VI: {VI_THRESHOLD}\")\n\nprint(\"\\\\nâœ… Variable Importance terminÃ©!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell_11"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"ğŸ¤– MODÃ‰LISATION: DÃ‰FINITION DES 8 MODÃˆLES\")\nprint(\"=\"*70)\n\n# Calculate mtry values\np = X_train.shape[1]\nmtry_sqrt = max(1, int(np.sqrt(p)))\nmtry_log = max(1, int(np.log(p)))\n\nprint(f\"\\\\nğŸ“Š ParamÃ¨tres mtry:\")\nprint(f\"   - p (total features): {p}\")\nprint(f\"   - âˆšp: {mtry_sqrt}\")\nprint(f\"   - log(p): {mtry_log:.2f} â†’ {mtry_log}\")\n\n# Define models\nmodels = {}\n\nif problem_type == 'classification':\n    models = {\n        '1. RLT-ExtraTrees': {\n            'model': ExtraTreesClassifier(**TREE_CONFIG),\n            'X_train': X_train_muted,\n            'X_test': X_test_muted,\n            'description': 'RLT avec Extra Trees + Variable Muting'\n        },\n        '2. RF': {\n            'model': RandomForestClassifier(**TREE_CONFIG),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': 'Random Forest classique'\n        },\n        '3. RF-âˆšp': {\n            'model': RandomForestClassifier(**{**TREE_CONFIG, 'max_features': mtry_sqrt}),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': f'Random Forest avec mtry = âˆšp = {mtry_sqrt}'\n        },\n        '4. RF-log(p)': {\n            'model': RandomForestClassifier(**{**TREE_CONFIG, 'max_features': mtry_log}),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': f'Random Forest avec mtry = log(p) = {mtry_log}'\n        },\n        '5. ExtraTrees': {\n            'model': ExtraTreesClassifier(**TREE_CONFIG),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': 'Extra Trees standard'\n        },\n        '6. LASSO': {\n            'model': LogisticRegression(penalty='l1', solver='liblinear', C=1/LASSO_CONFIG['alpha'], \n                                       random_state=RANDOM_STATE, max_iter=LASSO_CONFIG['max_iter']),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': 'Logistic Regression avec LASSO'\n        },\n        '7. XGBoost': {\n            'model': XGBClassifier(**XGBOOST_CONFIG),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': 'XGBoost Classifier'\n        },\n        '8. AdaBoost': {\n            'model': AdaBoostClassifier(**BOOSTING_CONFIG),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': 'AdaBoost Classifier'\n        }\n    }\nelse:  # Regression\n    models = {\n        '1. RLT-ExtraTrees': {\n            'model': ExtraTreesRegressor(**TREE_CONFIG),\n            'X_train': X_train_muted,\n            'X_test': X_test_muted,\n            'description': 'RLT avec Extra Trees + Variable Muting'\n        },\n        '2. RF': {\n            'model': RandomForestRegressor(**TREE_CONFIG),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': 'Random Forest classique'\n        },\n        '3. RF-âˆšp': {\n            'model': RandomForestRegressor(**{**TREE_CONFIG, 'max_features': mtry_sqrt}),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': f'Random Forest avec mtry = âˆšp = {mtry_sqrt}'\n        },\n        '4. RF-log(p)': {\n            'model': RandomForestRegressor(**{**TREE_CONFIG, 'max_features': mtry_log}),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': f'Random Forest avec mtry = log(p) = {mtry_log}'\n        },\n        '5. ExtraTrees': {\n            'model': ExtraTreesRegressor(**TREE_CONFIG),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': 'Extra Trees standard'\n        },\n        '6. LASSO': {\n            'model': Lasso(**LASSO_CONFIG),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': 'LASSO Regression'\n        },\n        '7. XGBoost': {\n            'model': XGBRegressor(**XGBOOST_CONFIG),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': 'XGBoost Regressor'\n        },\n        '8. GradientBoosting': {\n            'model': GradientBoostingRegressor(**BOOSTING_CONFIG),\n            'X_train': X_train,\n            'X_test': X_test,\n            'description': 'Gradient Boosting Regressor'\n        }\n    }\n\nprint(f\"\\\\nğŸ“‹ ModÃ¨les dÃ©finis:\")\nfor name, config in models.items():\n    print(f\"   {name}: {config['description']}\")\n    print(f\"      â†’ Features: {config['X_train'].shape[1]}\")\n\nprint(\"\\\\nâœ… ModÃ¨les configurÃ©s!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell_12"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"ğŸš€ ENTRAÃNEMENT DES 8 MODÃˆLES\")\nprint(\"=\"*70)\n\nresults = []\n\nfor model_name, config in models.items():\n    print(f\"\\\\n{'='*60}\")\n    print(f\"ğŸƒ EntraÃ®nement: {model_name}\")\n    print(f\"{'='*60}\")\n    \n    model = config['model']\n    X_tr = config['X_train']\n    X_te = config['X_test']\n    \n    print(f\"   ğŸ“Š Features utilisÃ©es: {X_tr.shape[1]}\")\n    print(f\"   â³ EntraÃ®nement en cours...\")\n    \n    start_time = time.time()\n    \n    # Train\n    model.fit(X_tr, y_train)\n    \n    # Predict\n    y_pred_train = model.predict(X_tr)\n    y_pred_test = model.predict(X_te)\n    \n    train_time = time.time() - start_time\n    \n    # Compute metrics\n    if problem_type == 'classification':\n        train_score = accuracy_score(y_train, y_pred_train)\n        test_score = accuracy_score(y_test, y_pred_test)\n        precision = precision_score(y_test, y_pred_test, average='weighted', zero_division=0)\n        recall = recall_score(y_test, y_pred_test, average='weighted', zero_division=0)\n        f1 = f1_score(y_test, y_pred_test, average='weighted', zero_division=0)\n        \n        print(f\"   âœ… TerminÃ© en {train_time:.2f}s\")\n        print(f\"   ğŸ“ˆ Train Accuracy: {train_score:.4f}\")\n        print(f\"   ğŸ“‰ Test Accuracy: {test_score:.4f}\")\n        print(f\"   ğŸ¯ Precision: {precision:.4f}\")\n        print(f\"   ğŸ¯ Recall: {recall:.4f}\")\n        print(f\"   ğŸ¯ F1-Score: {f1:.4f}\")\n        \n        results.append({\n            'Model': model_name,\n            'Features': X_tr.shape[1],\n            'Train_Accuracy': train_score,\n            'Test_Accuracy': test_score,\n            'Precision': precision,\n            'Recall': recall,\n            'F1_Score': f1,\n            'Train_Time': train_time\n        })\n    else:\n        train_score = r2_score(y_train, y_pred_train)\n        test_score = r2_score(y_test, y_pred_test)\n        rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n        mae = mean_absolute_error(y_test, y_pred_test)\n        \n        print(f\"   âœ… TerminÃ© en {train_time:.2f}s\")\n        print(f\"   ğŸ“ˆ Train RÂ²: {train_score:.4f}\")\n        print(f\"   ğŸ“‰ Test RÂ²: {test_score:.4f}\")\n        print(f\"   ğŸ¯ RMSE: {rmse:.4f}\")\n        print(f\"   ğŸ¯ MAE: {mae:.4f}\")\n        \n        results.append({\n            'Model': model_name,\n            'Features': X_tr.shape[1],\n            'Train_R2': train_score,\n            'Test_R2': test_score,\n            'RMSE': rmse,\n            'MAE': mae,\n            'Train_Time': train_time\n        })\n\nprint(f\"\\\\n{'='*60}\")\nprint(\"âœ… TOUS LES MODÃˆLES ENTRAÃNÃ‰S!\")\nprint(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell_13"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"ğŸ“Š COMPARAISON ANALYTIQUE DES RÃ‰SULTATS\")\nprint(\"=\"*70)\n\n# Create results DataFrame\nresults_df = pd.DataFrame(results)\n\nprint(\"\\\\nğŸ“‹ Tableau Complet des RÃ©sultats:\")\ndisplay(results_df)\n\n# Sort by test performance\nif problem_type == 'classification':\n    results_df_sorted = results_df.sort_values('Test_Accuracy', ascending=False)\n    best_model = results_df_sorted.iloc[0]\n    metric_name = 'Test Accuracy'\n    metric_col = 'Test_Accuracy'\nelse:\n    results_df_sorted = results_df.sort_values('Test_R2', ascending=False)\n    best_model = results_df_sorted.iloc[0]\n    metric_name = 'Test RÂ²'\n    metric_col = 'Test_R2'\n\nprint(f\"\\\\nğŸ† MEILLEUR MODÃˆLE:\")\nprint(f\"   - Nom: {best_model['Model']}\")\nprint(f\"   - {metric_name}: {best_model[metric_col]:.4f}\")\nprint(f\"   - Features: {best_model['Features']}\")\nprint(f\"   - Temps: {best_model['Train_Time']:.2f}s\")\n\n# Find RLT position\nrlt_position = results_df_sorted[results_df_sorted['Model'].str.contains('RLT')].index[0] + 1\nprint(f\"\\\\nğŸŒ² RLT-ExtraTrees:\")\nprint(f\"   - Position: #{rlt_position} / {len(results_df)}\")\nprint(f\"   - {metric_name}: {results_df[results_df['Model'].str.contains('RLT')].iloc[0][metric_col]:.4f}\")\n\n# Visualizations\nprint(\"\\\\nğŸ“Š GÃ©nÃ©ration des visualisations...\")\n\n# Plot 1: Performance comparison\nplt.figure(figsize=(14, 6))\nplt.subplot(1, 2, 1)\ncolors = ['red' if 'RLT' in name else 'steelblue' for name in results_df_sorted['Model']]\nplt.barh(range(len(results_df_sorted)), results_df_sorted[metric_col], color=colors)\nplt.yticks(range(len(results_df_sorted)), results_df_sorted['Model'])\nplt.xlabel(metric_name)\nplt.title(f'Comparaison des ModÃ¨les - {metric_name}', fontsize=14, fontweight='bold')\nplt.gca().invert_yaxis()\n\n# Plot 2: Training time\nplt.subplot(1, 2, 2)\nplt.barh(range(len(results_df_sorted)), results_df_sorted['Train_Time'], color=colors)\nplt.yticks(range(len(results_df_sorted)), results_df_sorted['Model'])\nplt.xlabel('Temps (secondes)')\nplt.title('Temps d EntraÃ®nement', fontsize=14, fontweight='bold')\nplt.gca().invert_yaxis()\n\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(f\"\\\\nğŸ“ˆ STATISTIQUES GLOBALES:\")\nprint(f\"   - Meilleur {metric_name}: {results_df[metric_col].max():.4f}\")\nprint(f\"   - Pire {metric_name}: {results_df[metric_col].min():.4f}\")\nprint(f\"   - Moyenne {metric_name}: {results_df[metric_col].mean():.4f}\")\nprint(f\"   - Ã‰cart-type: {results_df[metric_col].std():.4f}\")\n\n# Improvement analysis\nrlt_score = results_df[results_df['Model'].str.contains('RLT')].iloc[0][metric_col]\nbest_other_score = results_df[~results_df['Model'].str.contains('RLT')][metric_col].max()\nimprovement = ((rlt_score - best_other_score) / best_other_score) * 100\n\nprint(f\"\\\\nğŸ” ANALYSE RLT:\")\nif rlt_score > best_other_score:\n    print(f\"   âœ… RLT est MEILLEUR que les autres modÃ¨les\")\n    print(f\"   ğŸ“ˆ AmÃ©lioration: +{improvement:.2f}%\")\nelif abs(rlt_score - best_other_score) < 0.01:\n    print(f\"   â‰ˆ RLT est Ã‰QUIVALENT aux autres modÃ¨les\")\n    print(f\"   ğŸ“Š DiffÃ©rence: {improvement:+.2f}%\")\nelse:\n    print(f\"   âš ï¸  RLT est moins performant\")\n    print(f\"   ğŸ“‰ DiffÃ©rence: {improvement:.2f}%\")\n\nprint(f\"\\\\nğŸ’¡ CONCLUSION:\")\nprint(f\"   Le modÃ¨le {best_model['Model']} obtient les meilleures performances\")\nprint(f\"   avec un {metric_name} de {best_model[metric_col]:.4f}\")\nprint(f\"   RLT-ExtraTrees se classe #{rlt_position} sur {len(results_df)} modÃ¨les.\")\n\nprint(\"\\\\n\" + \"=\"*70)\nprint(\"âœ… ANALYSE COMPLÃˆTE TERMINÃ‰E!\")\nprint(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell_14"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"ğŸ’¾ SAUVEGARDE DES RÃ‰SULTATS\")\nprint(\"=\"*70\")\n\n# Save results to CSV\ncsv_filename = f\"results_{filename.replace('.csv', '')}.csv\"\nresults_df.to_csv(csv_filename, index=False)\nprint(f\"\\\\nâœ… RÃ©sultats sauvegardÃ©s: {csv_filename}\")\n\n# Download results\nfiles.download(csv_filename)\nprint(f\"ğŸ“¥ TÃ©lÃ©chargement du fichier de rÃ©sultats...\")\n\nprint(\"\\\\nğŸ‰ PROJET TERMINÃ‰!\")\nprint(f\"\\\\nğŸ“Š RÃ©sumÃ©:\")\nprint(f\"   - Dataset: {filename}\")\nprint(f\"   - Type: {problem_type.upper()}\")\nprint(f\"   - Samples: {df.shape[0]}\")\nprint(f\"   - Features (origin): {df.shape[1] - 1}\")\nprint(f\"   - Features (after prep): {X_train.shape[1]}\")\nprint(f\"   - Features (RLT muted): {X_train_muted.shape[1]}\")\nprint(f\"   - Models entraÃ®nÃ©s: 8\")\nprint(f\"   - Meilleur modÃ¨le: {best_model['Model']}\")\nprint(f\"   - Meilleur {metric_name}: {best_model[metric_col]:.4f}\")\nprint(f\"\\\\nâœ… Tous les rÃ©sultats ont Ã©tÃ© sauvegardÃ©s!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "RLT_Comparative_Study.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}