{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSO1: Impl√©mentation et √âvaluation de la M√©thodologie RLT\n",
    "## Reinforcement Learning Trees sur Donn√©es Multivari√©es\n",
    "\n",
    "**Authors:** Dhia Romdhane, Yosri Awedi, Baha Saadoui, Nour Rajhi, Bouguerra Taha, Oumaima Nacef  \n",
    "**Date:** December 2025  \n",
    "**Course:** Machine Learning Project - DSO1  \n",
    "**M√©thodologie:** CRISP-DM + RLT (Zhu et al., 2015)\n",
    "\n",
    "---\n",
    "\n",
    "## üìö √Ä propos de ce Notebook (DSO1)\n",
    "\n",
    "Ce notebook impl√©mente la **m√©thodologie RLT de base** :\n",
    "1. **Variable Importance (VI)** - Estimation de l'importance globale des variables\n",
    "2. **Variable Muting** - √âlimination des variables faibles\n",
    "3. **RLT avec Random Forest** - Mod√®le embarqu√© de base\n",
    "4. **Comparaison Baseline vs RLT** - √âvaluation des performances\n",
    "\n",
    "### üéØ Scope du DSO1\n",
    "- ‚úÖ **Mod√®le Na√Øf (Baseline)** : R√©gression/Classification simple\n",
    "- ‚úÖ **RLT-RandomForest** : Impl√©mentation RLT avec RF comme mod√®le embarqu√©\n",
    "- ‚úÖ **√âvaluation compl√®te** : M√©triques, visualisations, comparaisons\n",
    "\n",
    "### üöÄ DSO2 (Travail Futur)\n",
    "Le **DSO2** explorera d'autres mod√®les embarqu√©s:\n",
    "- üîú XGBoost\n",
    "- üîú LightGBM\n",
    "- üîú Extra Trees\n",
    "- üîú Gradient Boosting\n",
    "- üîú Neural Networks\n",
    "\n",
    "### üìä Datasets Support√©s\n",
    "Ce notebook fonctionne sur **9 datasets** + possibilit√© d'uploader vos propres donn√©es."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries (DSO1: Models simples + Random Forest)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, r2_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score\n",
    "from scipy.stats import f_classif, f_regression\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "VI_THRESHOLD = 0.01\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DSO1: Impl√©mentation RLT de Base\".center(80))\n",
    "print(\"=\"*80)\n",
    "print(\"‚úì Biblioth√®ques import√©es avec succ√®s!\")\n",
    "print(f\"üìÖ D√©marrage: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nüí° DSO1 Focus: Baseline + RLT-RandomForest\")\n",
    "print(f\"üîú DSO2 travaillera sur: XGBoost, LightGBM, Extra Trees, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìÇ S√©lection du Dataset\n",
    "\n",
    "**Option 1:** Choisir un dataset pr√©-charg√© (1-9)  \n",
    "**Option 2:** Uploader votre propre CSV (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets disponibles\n",
    "AVAILABLE_DATASETS = {\n",
    "    '1': {'file': 'BostonHousing.csv', 'target': 'medv', 'type': 'regression'},\n",
    "    '2': {'file': 'winequality-red.csv', 'target': 'quality', 'type': 'classification'},\n",
    "    '3': {'file': 'winequality-white.csv', 'target': 'quality', 'type': 'classification'},\n",
    "    '4': {'file': 'sonar data.csv', 'target': 'Class', 'type': 'classification'},\n",
    "    '5': {'file': 'parkinsons.data', 'target': 'status', 'type': 'classification'},\n",
    "    '6': {'file': 'wdbc.data', 'target': None, 'type': 'classification'},\n",
    "    '7': {'file': 'auto-mpg.data', 'target': 'mpg', 'type': 'regression'},\n",
    "    '8': {'file': 'data_school.csv', 'target': None, 'type': 'classification'},\n",
    "    '9': {'file': 'breast-cancer.csv', 'target': 'diagnosis', 'type': 'classification'}\n",
    "}\n",
    "\n",
    "print(\"üìä DATASETS DISPONIBLES:\")\n",
    "print(\"=\"*80)\n",
    "for key, info in AVAILABLE_DATASETS.items():\n",
    "    print(f\"{key}. {info['file']:<30} Type: {info['type']:<15} Target: {info['target'] or 'Auto'}\")\n",
    "print(\"\\n0. Uploader votre propre CSV\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(choice='1'):\n",
    "    \"\"\"\n",
    "    Charger un dataset selon le choix.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df, target_col, problem_type\n",
    "    \"\"\"\n",
    "    if choice == '0':\n",
    "        print(\"üì§ Mode Upload: Uploadez votre fichier CSV\")\n",
    "        print(\"‚ö†Ô∏è Apr√®s upload, ex√©cutez la cellule suivante pour traiter le fichier\")\n",
    "        return None, None, None\n",
    "    \n",
    "    elif choice in AVAILABLE_DATASETS:\n",
    "        dataset_info = AVAILABLE_DATASETS[choice]\n",
    "        filepath = dataset_info['file']\n",
    "        \n",
    "        try:\n",
    "            # Charger le fichier\n",
    "            if filepath.endswith('.data'):\n",
    "                df = pd.read_csv(filepath, header=None if 'wdbc' in filepath else 0)\n",
    "            else:\n",
    "                df = pd.read_csv(filepath)\n",
    "            \n",
    "            # D√©terminer la colonne cible\n",
    "            if dataset_info['target']:\n",
    "                target_col = dataset_info['target']\n",
    "            elif 'wdbc' in filepath:\n",
    "                target_col = df.columns[1]\n",
    "                df = df.iloc[:, 1:]\n",
    "            else:\n",
    "                target_col = df.columns[-1]\n",
    "            \n",
    "            problem_type = dataset_info['type']\n",
    "            \n",
    "            print(f\"‚úì Dataset charg√©: {filepath}\")\n",
    "            print(f\"  Forme: {df.shape}\")\n",
    "            print(f\"  Cible: {target_col}\")\n",
    "            print(f\"  Type: {problem_type}\")\n",
    "            \n",
    "            return df, target_col, problem_type\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur lors du chargement de {filepath}: {e}\")\n",
    "            return None, None, None\n",
    "    else:\n",
    "        print(\"‚ùå Choix invalide\")\n",
    "        return None, None, None\n",
    "\n",
    "# CHANGEZ CE NUM√âRO pour tester diff√©rents datasets (1-9)\n",
    "DATASET_CHOICE = '1'\n",
    "\n",
    "df, target_col, problem_type = load_dataset(DATASET_CHOICE)\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"\\nüìä Aper√ßu du Dataset:\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîç Analyse Exploratoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"üìä INFORMATIONS SUR LE DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Forme: {df.shape[0]} √©chantillons, {df.shape[1]} caract√©ristiques\")\n",
    "    print(f\"Cible: {target_col}\")\n",
    "    print(f\"Type de probl√®me: {problem_type}\")\n",
    "    print(f\"\\nValeurs manquantes: {df.isnull().sum().sum()}\")\n",
    "    print(f\"Doublons: {df.duplicated().sum()}\")\n",
    "    \n",
    "    print(\"\\nüìà Distribution de la cible:\")\n",
    "    if problem_type == 'classification':\n",
    "        print(df[target_col].value_counts())\n",
    "    else:\n",
    "        print(df[target_col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations\n",
    "if df is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Distribution de la cible\n",
    "    if problem_type == 'classification':\n",
    "        df[target_col].value_counts().plot(kind='bar', ax=axes[0], color='steelblue', alpha=0.7)\n",
    "        axes[0].set_title('Distribution des Classes', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_ylabel('Nombre')\n",
    "    else:\n",
    "        axes[0].hist(df[target_col], bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "        axes[0].set_title('Distribution de la Cible', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_ylabel('Fr√©quence')\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Heatmap de corr√©lation\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr_matrix = df[numeric_cols].corr()\n",
    "        if target_col in corr_matrix.columns:\n",
    "            top_features = corr_matrix[target_col].abs().nlargest(min(10, len(corr_matrix))).index\n",
    "            sns.heatmap(df[top_features].corr(), annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                       center=0, ax=axes[1], square=True)\n",
    "            axes[1].set_title('Matrice de Corr√©lation (Top Features)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üõ†Ô∏è RLT √âTAPE 1: Pr√©traitement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"üîß PR√âTRAITEMENT DES DONN√âES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # S√©parer features et cible\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Encoder les variables cat√©gorielles\n",
    "    categorical_features = X.select_dtypes(exclude=[np.number]).columns\n",
    "    if len(categorical_features) > 0:\n",
    "        print(f\"‚ö†Ô∏è Encodage de {len(categorical_features)} variables cat√©gorielles...\")\n",
    "        for col in categorical_features:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "    \n",
    "    # Encoder la cible si classification\n",
    "    if problem_type == 'classification':\n",
    "        if y.dtype == 'object' or not np.issubdtype(y.dtype, np.number):\n",
    "            le_target = LabelEncoder()\n",
    "            y = le_target.fit_transform(y)\n",
    "    \n",
    "    # Standardiser les features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    print(f\"\\n‚úì Pr√©traitement termin√©\")\n",
    "    print(f\"  Features: {X_scaled.shape[1]}\")\n",
    "    print(f\"  √âchantillons: {len(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† RLT √âTAPE 2: Calcul de Variable Importance (VI)\n",
    "\n",
    "**M√©thodologie RLT (Zhu et al., 2015):**\n",
    "1. Random Forest feature importance (40%)\n",
    "2. Tests statistiques F-statistic/corr√©lation (60%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"üß† CALCUL DE VARIABLE IMPORTANCE (VI)\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nM√©thode: Random Forest (40%) + Tests Statistiques (60%)\")\n",
    "    \n",
    "    # M√©thode 1: Random Forest VI\n",
    "    if problem_type == 'classification':\n",
    "        rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        f_scores, _ = f_classif(X_scaled, y)\n",
    "    else:\n",
    "        rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        f_scores, _ = f_regression(X_scaled, y)\n",
    "    \n",
    "    rf.fit(X_scaled, y)\n",
    "    vi_rf = rf.feature_importances_\n",
    "    \n",
    "    # M√©thode 2: VI Statistique\n",
    "    vi_stat = np.abs(f_scores)\n",
    "    \n",
    "    # Normaliser\n",
    "    vi_rf = vi_rf / vi_rf.sum()\n",
    "    vi_stat = vi_stat / vi_stat.sum()\n",
    "    \n",
    "    # Agr√©ger (RLT DSO1: RF 40% + Stat 60%)\n",
    "    VI_RF_WEIGHT = 0.4\n",
    "    VI_STAT_WEIGHT = 0.6\n",
    "    \n",
    "    vi_aggregate = VI_RF_WEIGHT * vi_rf + VI_STAT_WEIGHT * vi_stat\n",
    "    \n",
    "    # DataFrame VI\n",
    "    vi_df = pd.DataFrame({\n",
    "        'Feature': X_scaled.columns,\n",
    "        'VI_RandomForest': vi_rf,\n",
    "        'VI_Statistical': vi_stat,\n",
    "        'VI_Aggregate': vi_aggregate\n",
    "    }).sort_values('VI_Aggregate', ascending=False)\n",
    "    \n",
    "    print(\"\\nüìä Top 10 Features par Importance:\")\n",
    "    display(vi_df.head(10))\n",
    "    \n",
    "    print(\"\\n‚úì Variable Importance calcul√©e (DSO1: RF + Statistical)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation VI\n",
    "if df is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Top 10 features\n",
    "    top_10 = vi_df.head(10)\n",
    "    axes[0].barh(range(len(top_10)), top_10['VI_Aggregate'], color='steelblue', alpha=0.8)\n",
    "    axes[0].set_yticks(range(len(top_10)))\n",
    "    axes[0].set_yticklabels(top_10['Feature'])\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_xlabel('Variable Importance (Agr√©g√©e)', fontsize=12)\n",
    "    axes[0].set_title('Top 10 Features - RLT Variable Importance', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Comparaison RF vs Statistical\n",
    "    x = np.arange(len(top_10))\n",
    "    width = 0.35\n",
    "    axes[1].barh(x - width/2, top_10['VI_RandomForest'], width, label='Random Forest (40%)', alpha=0.8)\n",
    "    axes[1].barh(x + width/2, top_10['VI_Statistical'], width, label='Statistical (60%)', alpha=0.8)\n",
    "    axes[1].set_yticks(x)\n",
    "    axes[1].set_yticklabels(top_10['Feature'])\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_xlabel('Variable Importance', fontsize=12)\n",
    "    axes[1].set_title('Comparaison des M√©thodes VI', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîá RLT √âTAPE 3: Variable Muting (√âlimination de Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(f\"üîá APPLICATION DU VARIABLE MUTING (seuil = {VI_THRESHOLD})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Identifier features √† garder\n",
    "    high_vi_features = vi_df[vi_df['VI_Aggregate'] >= VI_THRESHOLD]['Feature'].tolist()\n",
    "    low_vi_features = vi_df[vi_df['VI_Aggregate'] < VI_THRESHOLD]['Feature'].tolist()\n",
    "    \n",
    "    # Garantir au moins 5 features\n",
    "    if len(high_vi_features) < 5:\n",
    "        high_vi_features = vi_df.head(5)['Feature'].tolist()\n",
    "        low_vi_features = vi_df.iloc[5:]['Feature'].tolist()\n",
    "        print(\"‚ö†Ô∏è Moins de 5 features au-dessus du seuil, conservation des 5 meilleures\")\n",
    "    \n",
    "    # Cr√©er dataset mut√©\n",
    "    X_muted = X_scaled[high_vi_features]\n",
    "    \n",
    "    muted_count = len(low_vi_features)\n",
    "    muted_pct = (muted_count / X_scaled.shape[1]) * 100\n",
    "    \n",
    "    print(f\"\\nüìä R√©sultats du Muting:\")\n",
    "    print(f\"  ‚Ä¢ Features Originales: {X_scaled.shape[1]}\")\n",
    "    print(f\"  ‚Ä¢ Features Conserv√©es: {len(high_vi_features)} ({100-muted_pct:.1f}%)\")\n",
    "    print(f\"  ‚Ä¢ Features Mut√©es: {muted_count} ({muted_pct:.1f}%)\")\n",
    "    \n",
    "    if muted_count > 0 and muted_count <= 10:\n",
    "        print(f\"\\nüîá Features Mut√©es (VI faible):\")\n",
    "        for feat in low_vi_features[:10]:\n",
    "            vi_value = vi_df[vi_df['Feature'] == feat]['VI_Aggregate'].values[0]\n",
    "            print(f\"    ‚Ä¢ {feat}: VI = {vi_value:.4f}\")\n",
    "    \n",
    "    print(f\"\\n‚úì Variable Muting termin√© - R√©duction: {muted_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§ñ RLT √âTAPE 4: Entra√Ænement des Mod√®les\n",
    "\n",
    "### DSO1 - Mod√®les de Base:\n",
    "1. **Baseline (Na√Øf)** - R√©gression/Classification simple sur toutes les features\n",
    "2. **RLT-RandomForest** - Random Forest sur features mut√©es\n",
    "\n",
    "### DSO2 (Futur) - Autres Mod√®les Embarqu√©s:\n",
    "- XGBoost, LightGBM, Extra Trees, Gradient Boosting, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"=\"*80)\n",
    "    print(\"DSO1: ENTRA√éNEMENT DES MOD√àLES\".center(80))\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nüìå Mod√®les DSO1:\")\n",
    "    print(\"  1. Baseline (Na√Øf) - Toutes les features\")\n",
    "    print(\"  2. RLT-RandomForest - Features mut√©es\")\n",
    "    print(\"\\nüîú DSO2 explorera: XGBoost, LightGBM, Extra Trees, etc.\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Configuration selon le type de probl√®me\n",
    "    if problem_type == 'classification':\n",
    "        baseline_model = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
    "        rlt_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'accuracy'\n",
    "        metric_name = 'Accuracy'\n",
    "    else:\n",
    "        baseline_model = LinearRegression()\n",
    "        rlt_model = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'r2'\n",
    "        metric_name = 'R¬≤'\n",
    "    \n",
    "    # Entra√Ænement Baseline (toutes features)\n",
    "    print(\"\\nüìä BASELINE (Mod√®le Na√Øf) - Toutes les features:\")\n",
    "    print(\"-\" * 60)\n",
    "    baseline_scores = cross_val_score(baseline_model, X_scaled, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    baseline_mean = baseline_scores.mean()\n",
    "    baseline_std = baseline_scores.std()\n",
    "    print(f\"  {metric_name} = {baseline_mean:.4f} (¬±{baseline_std:.4f})\")\n",
    "    print(f\"  Nombre de features: {X_scaled.shape[1]}\")\n",
    "    \n",
    "    # Entra√Ænement RLT (features mut√©es)\n",
    "    print(\"\\nüìä RLT-RANDOMFOREST - Features mut√©es:\")\n",
    "    print(\"-\" * 60)\n",
    "    rlt_scores = cross_val_score(rlt_model, X_muted, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    rlt_mean = rlt_scores.mean()\n",
    "    rlt_std = rlt_scores.std()\n",
    "    print(f\"  {metric_name} = {rlt_mean:.4f} (¬±{rlt_std:.4f})\")\n",
    "    print(f\"  Nombre de features: {X_muted.shape[1]}\")\n",
    "    \n",
    "    # Stocker les r√©sultats\n",
    "    results = {\n",
    "        'Baseline': {'mean': baseline_mean, 'std': baseline_std, 'n_features': X_scaled.shape[1]},\n",
    "        'RLT-RandomForest': {'mean': rlt_mean, 'std': rlt_std, 'n_features': X_muted.shape[1]}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä RLT √âTAPE 5: √âvaluation et Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARAISON FINALE: BASELINE vs RLT\".center(80))\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Calcul de l'am√©lioration\n",
    "    improvement = ((rlt_mean - baseline_mean) / baseline_mean) * 100\n",
    "    feature_reduction = muted_pct\n",
    "    \n",
    "    # Affichage comparatif\n",
    "    print(f\"\\nüèÜ R√âSULTATS DSO1:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"  Baseline (Na√Øf):         {metric_name} = {baseline_mean:.4f} (¬±{baseline_std:.4f})\")\n",
    "    print(f\"                           Features: {X_scaled.shape[1]}\")\n",
    "    print()\n",
    "    print(f\"  RLT-RandomForest:        {metric_name} = {rlt_mean:.4f} (¬±{rlt_std:.4f})\")\n",
    "    print(f\"                           Features: {X_muted.shape[1]} (r√©duction: {feature_reduction:.1f}%)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    print(f\"\\nüí° ANALYSE:\")\n",
    "    print(f\"  Am√©lioration RLT:        {improvement:+.2f}%\")\n",
    "    print(f\"  R√©duction de features:   {feature_reduction:.1f}%\")\n",
    "    \n",
    "    winner = \"RLT-RandomForest\" if rlt_mean > baseline_mean else \"Baseline\"\n",
    "    winner_icon = \"üéØ\" if winner == \"RLT-RandomForest\" else \"‚ö†Ô∏è\"\n",
    "    print(f\"\\n{winner_icon} GAGNANT: {winner}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üí¨ CONCLUSION DSO1:\")\n",
    "    if rlt_mean > baseline_mean:\n",
    "        print(f\"  ‚úÖ RLT am√©liore les performances de {improvement:.2f}%\")\n",
    "        print(f\"  ‚úÖ Avec {feature_reduction:.1f}% de features en moins!\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è Baseline meilleur de {abs(improvement):.2f}%\")\n",
    "        print(f\"  üí° RLT peut mieux fonctionner sur datasets haute dimension\")\n",
    "    print(\"\\nüîú DSO2 testera d'autres mod√®les embarqu√©s (XGBoost, LightGBM, etc.)\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la comparaison\n",
    "if df is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Graphique 1: Comparaison des performances\n",
    "    models = ['Baseline\\n(Na√Øf)', 'RLT-\\nRandomForest']\n",
    "    scores = [baseline_mean, rlt_mean]\n",
    "    colors = ['steelblue', 'orange']\n",
    "    \n",
    "    bars = axes[0].bar(models, scores, color=colors, alpha=0.7, edgecolor='black', width=0.6)\n",
    "    axes[0].set_ylabel(f'{metric_name} Score', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('DSO1: Baseline vs RLT-RandomForest', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylim([min(scores) * 0.95, max(scores) * 1.05])\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar, score in zip(bars, scores):\n",
    "        height = bar.get_height()\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{score:.4f}', ha='center', va='bottom', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Graphique 2: Am√©lioration et r√©duction de features\n",
    "    metrics = ['Performance\\nImprovement (%)', 'Feature\\nReduction (%)']\n",
    "    values = [improvement, feature_reduction]\n",
    "    colors2 = ['green' if improvement > 0 else 'red', 'blue']\n",
    "    \n",
    "    bars = axes[1].bar(metrics, values, color=colors2, alpha=0.7, edgecolor='black', width=0.6)\n",
    "    axes[1].axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    axes[1].set_ylabel('Pourcentage (%)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('RLT: Am√©lioration vs R√©duction', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Ajouter les valeurs\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{value:+.1f}%' if 'Improvement' in bar.get_x() else f'{value:.1f}%',\n",
    "                    ha='center', va='bottom' if height > 0 else 'top',\n",
    "                    fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìà √âvaluation D√©taill√©e sur Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"üìà √âVALUATION SUR ENSEMBLE DE TEST\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Split train/test\n",
    "    X_train_full, X_test_full, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=RANDOM_STATE, \n",
    "        stratify=y if problem_type == 'classification' else None\n",
    "    )\n",
    "    \n",
    "    X_train_muted = X_train_full[high_vi_features]\n",
    "    X_test_muted = X_test_full[high_vi_features]\n",
    "    \n",
    "    # Entra√Æner et pr√©dire\n",
    "    baseline_model.fit(X_train_full, y_train)\n",
    "    rlt_model.fit(X_train_muted, y_train)\n",
    "    \n",
    "    y_pred_baseline = baseline_model.predict(X_test_full)\n",
    "    y_pred_rlt = rlt_model.predict(X_test_muted)\n",
    "    \n",
    "    # M√©triques\n",
    "    if problem_type == 'classification':\n",
    "        baseline_score = accuracy_score(y_test, y_pred_baseline)\n",
    "        rlt_score = accuracy_score(y_test, y_pred_rlt)\n",
    "        \n",
    "        print(f\"\\nüéØ Accuracy sur Test Set:\")\n",
    "        print(f\"  Baseline:        {baseline_score:.4f}\")\n",
    "        print(f\"  RLT-RandomForest: {rlt_score:.4f}\")\n",
    "        print(f\"  Diff√©rence:      {(rlt_score - baseline_score):.4f}\")\n",
    "        \n",
    "        print(f\"\\nüìä Classification Report (RLT):\")\n",
    "        print(classification_report(y_test, y_pred_rlt))\n",
    "    else:\n",
    "        baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "        rlt_r2 = r2_score(y_test, y_pred_rlt)\n",
    "        \n",
    "        baseline_rmse = np.sqrt(mean_squared_error(y_test, y_pred_baseline))\n",
    "        rlt_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rlt))\n",
    "        \n",
    "        print(f\"\\nüéØ M√©triques sur Test Set:\")\n",
    "        print(f\"\\n  R¬≤ Score:\")\n",
    "        print(f\"    Baseline:         {baseline_r2:.4f}\")\n",
    "        print(f\"    RLT-RandomForest: {rlt_r2:.4f}\")\n",
    "        print(f\"  \\n  RMSE:\")\n",
    "        print(f\"    Baseline:         {baseline_rmse:.4f}\")\n",
    "        print(f\"    RLT-RandomForest: {rlt_rmse:.4f}\")\n",
    "    \n",
    "    test_improvement = ((rlt_score if problem_type == 'classification' else rlt_r2) - \n",
    "                       (baseline_score if problem_type == 'classification' else baseline_r2)) / \\\n",
    "                      (baseline_score if problem_type == 'classification' else baseline_r2) * 100\n",
    "    \n",
    "    print(f\"\\nüí° Am√©lioration sur Test: {test_improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üíæ Sauvegarder les R√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Cr√©er un r√©sum√©\n",
    "    summary = pd.DataFrame({\n",
    "        'Model': ['Baseline (Na√Øf)', 'RLT-RandomForest'],\n",
    "        'Score_Mean': [baseline_mean, rlt_mean],\n",
    "        'Score_Std': [baseline_std, rlt_std],\n",
    "        'N_Features': [X_scaled.shape[1], X_muted.shape[1]],\n",
    "        'Dataset': [AVAILABLE_DATASETS[DATASET_CHOICE]['file']] * 2,\n",
    "        'Problem_Type': [problem_type] * 2\n",
    "    })\n",
    "    \n",
    "    output_file = f\"DSO1_Results_{AVAILABLE_DATASETS[DATASET_CHOICE]['file'].replace('.', '_')}.csv\"\n",
    "    summary.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"üíæ R√©sultats sauvegard√©s: {output_file}\")\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Conclusions DSO1\n",
    "\n",
    "### üéØ Ce que nous avons accompli (DSO1):\n",
    "\n",
    "1. **‚úÖ Impl√©mentation RLT compl√®te:**\n",
    "   - Variable Importance (RF + Statistical)\n",
    "   - Variable Muting\n",
    "   - Comparaison Baseline vs RLT\n",
    "\n",
    "2. **‚úÖ Mod√®les DSO1:**\n",
    "   - Baseline Na√Øf (Logistic/Linear Regression)\n",
    "   - RLT-RandomForest\n",
    "\n",
    "3. **‚úÖ √âvaluation rigoureuse:**\n",
    "   - Cross-validation 5-fold\n",
    "   - Test set evaluation\n",
    "   - M√©triques multiples\n",
    "   - Visualisations\n",
    "\n",
    "### üöÄ Pour DSO2 (Travail Futur):\n",
    "\n",
    "Le **DSO2** explorera d'autres mod√®les embarqu√©s pour RLT:\n",
    "\n",
    "**Mod√®les √† tester:**\n",
    "- üîú **XGBoost** - Gradient boosting optimis√©\n",
    "- üîú **LightGBM** - Gradient boosting rapide\n",
    "- üîú **Extra Trees** - Variation de Random Forest\n",
    "- üîú **Gradient Boosting** - Boosting classique\n",
    "- üîú **CatBoost** - Pour variables cat√©gorielles\n",
    "- üîú **Neural Networks** - Approche deep learning\n",
    "\n",
    "**Pistes d'am√©lioration DSO2:**\n",
    "- Feature Engineering avanc√©\n",
    "- Hyperparameter tuning\n",
    "- Stacking de mod√®les\n",
    "- Feature combinations (interactions)\n",
    "\n",
    "### üìö Recommandations:\n",
    "\n",
    "**Quand utiliser RLT:**\n",
    "- ‚úÖ Datasets avec > 20 features\n",
    "- ‚úÖ Pr√©sence de variables bruit√©es\n",
    "- ‚úÖ Besoin d'interpr√©tabilit√©\n",
    "- ‚úÖ Contraintes de vitesse (moins de features)\n",
    "\n",
    "**Quand √©viter RLT:**\n",
    "- ‚ö†Ô∏è Datasets avec < 10 features\n",
    "- ‚ö†Ô∏è Toutes les features sont importantes\n",
    "- ‚ö†Ô∏è √âchantillons tr√®s petits (n < 100)\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ R√©f√©rences\n",
    "\n",
    "1. **Zhu, R., Zeng, D., & Kosorok, M. R. (2015).** \"Reinforcement Learning Trees.\" *Journal of the American Statistical Association*, 110(512), 1770-1784.\n",
    "\n",
    "2. **Breiman, L. (2001).** \"Random Forests.\" *Machine Learning*, 45(1), 5-32.\n",
    "\n",
    "3. **CRISP-DM Methodology** - Cross-Industry Standard Process for Data Mining\n",
    "\n",
    "---\n",
    "\n",
    "**Authors:** Dhia Romdhane, Yosri Awedi, Baha Saadoui, Nour Rajhi, Bouguerra Taha, Oumaima Nacef  \n",
    "**Course:** Machine Learning Project - DSO1  \n",
    "**Date:** December 2025  \n",
    "**Repository:** https://github.com/yosriawedi/ML-Project-RLT\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ DSO1 Termin√©!\n",
    "\n",
    "Ce notebook a d√©montr√© l'**impl√©mentation et l'√©valuation de base de la m√©thodologie RLT**.\n",
    "\n",
    "**Prochaine √©tape:** DSO2 explorera d'autres mod√®les embarqu√©s! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
