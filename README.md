# ğŸŒ² RLT Extra Trees: Ã‰tude Comparative ComplÃ¨te
## Reinforcement Learning Trees - Analyse Multi-ModÃ¨les

**Author:** Dhia Romdhane  
**Date:** December 2025  
**Repository:** https://github.com/yosriawedi/ML-Project-RLT

---

## ğŸ¯ Objectif

Comparer **RLT-ExtraTrees** (Reinforcement Learning Trees) contre 7 autres modÃ¨les de rÃ©fÃ©rence sur n'importe quel dataset uploadÃ©.

### ModÃ¨les ComparÃ©s (8 au total):

1. **RLT-ExtraTrees** - RLT avec Variable Importance + Muting
2. **RF** - Random Forest classique  
3. **RF-âˆšp** - Random Forest avec mtry = âˆšp
4. **RF-log(p)** - Random Forest avec mtry = log(p)
5. **ExtraTrees** - Extra Trees standard
6. **BART/AdaBoost** - Bayesian/Adaptive Boosting
7. **LASSO** - RÃ©gression LASSO
8. **XGBoost** - Gradient Boosting

---

## ğŸ“Š MÃ©thodologie

### CRISP-DM (Cross-Industry Standard Process for Data Mining)

1. **Business Understanding** - DÃ©finition du problÃ¨me
2. **Data Understanding** - Analyse exploratoire (EDA)
3. **Data Preparation** - Preprocessing + Feature Engineering
4. **Modeling** - EntraÃ®nement des 8 modÃ¨les
5. **Evaluation** - Comparaison analytique
6. **Deployment** - Sauvegarde des rÃ©sultats

### HyperparamÃ¨tres FIXES

Tous les modÃ¨les utilisent les **mÃªmes hyperparamÃ¨tres** (fixÃ©s avant modÃ©lisation) pour une comparaison Ã©quitable:

```python
# Configuration globale
RANDOM_STATE = 42
TEST_SIZE = 0.2
CV_FOLDS = 5

# Tree-based models
n_estimators = 100
max_depth = None
min_samples_split = 2
min_samples_leaf = 1

# RLT
VI_THRESHOLD = 0.01
VI_EXTRA_TREES_WEIGHT = 0.5
VI_STAT_WEIGHT = 0.5
```

---

## ğŸš€ Comment Utiliser

### Option 1: Google Colab (RECOMMANDÃ‰)

1. **Ouvrir Google Colab**: https://colab.research.google.com/

2. **CrÃ©er un nouveau notebook**

3. **Copier le contenu de `RLT_Complete_Analysis.py`** dans Colab

4. **DÃ©couper en cellules**:
   - Chercher les lignes avec `# ===... CELLULE X`
   - CrÃ©er une nouvelle cellule pour chaque section

5. **ExÃ©cuter cellule par cellule** (Shift+Enter)

6. **Upload votre dataset CSV** quand demandÃ© (Cellule 4)

7. **Attendre les rÃ©sultats** et visualisations

### Option 2: Utiliser le fichier Python directement

```python
# Dans Colab, crÃ©ez une cellule et exÃ©cutez:
!wget https://raw.githubusercontent.com/yosriawedi/ML-Project-RLT/main/RLT_Complete_Analysis.py

# Puis copiez-collez le contenu dans des cellules
```

---

## ğŸ“ Format de Dataset Attendu

### Structure du CSV:

```
feature1, feature2, feature3, ..., target
1.2,      3.4,      5.6,      ..., 0
2.3,      4.5,      6.7,      ..., 1
...
```

### RÃ¨gles:

- âœ… **Format**: CSV avec header
- âœ… **DerniÃ¨re colonne**: Target (variable Ã  prÃ©dire)
- âœ… **Autres colonnes**: Features
- âœ… **Valeurs manquantes**: AcceptÃ©es (seront traitÃ©es automatiquement)
- âœ… **Variables catÃ©gorielles**: AcceptÃ©es (seront encodÃ©es)

### Exemples de datasets compatibles:

- Iris
- Boston Housing
- Breast Cancer
- Wine Quality
- Diabetes
- Titanic
- N'importe quel dataset classification/rÃ©gression!

---

## ğŸ“Š Ce Que Vous Obtenez

### 1. Data Understanding (EDA)

- Statistiques descriptives
- Distribution du target
- Valeurs manquantes
- Doublons
- Matrice de corrÃ©lation
- Distribution des features

### 2. Data Preparation

- Nettoyage automatique
- Encoding catÃ©gorielles
- Scaling (StandardScaler)
- Split train/test (80/20)

### 3. RLT Variable Importance

- Calcul VI avec Extra Trees (50%) + Tests Statistiques (50%)
- Ranking de toutes les features
- Variable Muting (seuil = 0.01)
- Visualisation des top features

### 4. ModÃ©lisation

- EntraÃ®nement de 8 modÃ¨les
- MÃ©triques pour chaque modÃ¨le:
  - **Classification**: Accuracy, Precision, Recall, F1-Score
  - **RÃ©gression**: RÂ², RMSE, MAE
- Temps d'entraÃ®nement

### 5. Comparaison Analytique

- Tableau complet des rÃ©sultats
- Ranking des modÃ¨les
- Visualisations comparatives
- Analyse de la performance de RLT
- Conclusion avec recommandations

### 6. RÃ©sultats SauvegardÃ©s

- Fichier CSV avec tous les rÃ©sultats
- TÃ©lÃ©chargement automatique

---

## ğŸ¯ Exemple de Sortie

```
=============================================================================
ğŸ“Š COMPARAISON ANALYTIQUE DES RÃ‰SULTATS
=============================================================================

ğŸ“‹ Tableau Complet des RÃ©sultats:

Model              Features  Train_Accuracy  Test_Accuracy  Precision  Recall  F1_Score  Train_Time
-----------------  --------  --------------  -------------  ---------  ------  --------  ----------
1. RLT-ExtraTrees  15        0.9876          0.9543         0.9534     0.9543  0.9538    2.34
2. RF              25        0.9923          0.9487         0.9481     0.9487  0.9484    3.12
3. RF-âˆšp           25        0.9845          0.9456         0.9449     0.9456  0.9452    2.98
4. RF-log(p)       25        0.9834          0.9423         0.9418     0.9423  0.9420    2.87
5. ExtraTrees      25        0.9912          0.9398         0.9392     0.9398  0.9395    3.45
6. LASSO           25        0.8567          0.8234         0.8229     0.8234  0.8231    0.45
7. XGBoost         25        0.9901          0.9512         0.9507     0.9512  0.9509    4.23
8. AdaBoost        25        0.9234          0.8987         0.8982     0.8987  0.8984    2.67

ğŸ† MEILLEUR MODÃˆLE:
   - Nom: 1. RLT-ExtraTrees
   - Test Accuracy: 0.9543
   - Features: 15 (40% rÃ©duction!)
   - Temps: 2.34s

ğŸŒ² RLT-ExtraTrees:
   - Position: #1 / 8
   - Test Accuracy: 0.9543

ğŸ” ANALYSE RLT:
   âœ… RLT est MEILLEUR que les autres modÃ¨les
   ğŸ“ˆ AmÃ©lioration: +0.59%
   ğŸš€ Avec 40% moins de features!

ğŸ’¡ CONCLUSION:
   RLT-ExtraTrees obtient les meilleures performances avec 0.9543
   et utilise seulement 15/25 features (60% des features originales)
```

---

## ğŸ“ˆ InterprÃ©tation des RÃ©sultats

### Si RLT Gagne:

âœ… **RLT est efficace** pour ce dataset  
âœ… **Variable Importance** a bien identifiÃ© les features importantes  
âœ… **Variable Muting** a Ã©liminÃ© le bruit sans perdre d'information  
âœ… **RÃ©duction de features** = ModÃ¨le plus rapide et interprÃ©table

### Si RLT Perd:

âš ï¸ **Toutes les features sont importantes** - pas de bruit Ã  Ã©liminer  
âš ï¸ **Dataset trop petit** - VI pas assez fiable  
âš ï¸ **Features faiblement corrÃ©lÃ©es** - Muting trop agressif  

â†’ Essayez d'ajuster `VI_THRESHOLD` (actuellement 0.01)

---

## âš™ï¸ Personnalisation

Vous pouvez modifier les hyperparamÃ¨tres dans **CELLULE 3**:

```python
# Changer le seuil de muting
VI_THRESHOLD = 0.01  # Plus bas = garde plus de features

# Changer les poids de VI
VI_EXTRA_TREES_WEIGHT = 0.5  # 0 Ã  1
VI_STAT_WEIGHT = 0.5          # 0 Ã  1 (total = 1)

# Changer le nombre d'arbres
TREE_CONFIG['n_estimators'] = 100  # Plus = mieux mais plus lent

# Changer le test size
TEST_SIZE = 0.2  # 20% test, 80% train
```

---

## ğŸ”§ DÃ©pendances

Toutes installÃ©es automatiquement dans Colab:

```python
pandas
numpy
scikit-learn
xgboost
matplotlib
seaborn
scipy
```

---

## ğŸ“š RÃ©fÃ©rences

1. **Zhu, R., Zeng, D., & Kosorok, M. R. (2015)**  
   "Reinforcement Learning Trees"  
   *Journal of the American Statistical Association*, 110(512), 1770-1784.

2. **Breiman, L. (2001)**  
   "Random Forests"  
   *Machine Learning*, 45(1), 5-32.

3. **CRISP-DM (2000)**  
   "Cross-Industry Standard Process for Data Mining"

---

## ğŸ“ Contact

**Author:** Dhia Romdhane  
**Repository:** https://github.com/yosriawedi/ML-Project-RLT  
**Issues:** https://github.com/yosriawedi/ML-Project-RLT/issues

---

## ğŸ“ License

Ce projet est Ã  usage acadÃ©mique.

---

## ğŸ‰ Changelog

### Version 1.0 (December 2025)
- âœ… Upload de dataset CSV
- âœ… Data Understanding (CRISP-DM)
- âœ… Data Preparation (CRISP-DM)
- âœ… RLT Variable Importance (Extra Trees + Statistical)
- âœ… 8 modÃ¨les comparÃ©s
- âœ… HyperparamÃ¨tres fixes
- âœ… Comparaison analytique complÃ¨te
- âœ… Visualisations
- âœ… Sauvegarde rÃ©sultats CSV

---

**ğŸš€ PrÃªt Ã  commencer? Uploadez votre dataset et lancez l'analyse!**
