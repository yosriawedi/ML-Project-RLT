{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üå≤ RLT Complete Study (Quick Mode)\n",
        "**Author:** Dhia Romdhane\n",
        "\n",
        "## üìä Objectives\n",
        "\n",
        "### Part 1: Real Dataset Upload & Preprocessing\n",
        "- Upload CSV dataset\n",
        "- Data cleaning, encoding, scaling\n",
        "- Train/test split\n",
        "\n",
        "### Part 2: Simulation Study (4 Scenarios)\n",
        "- **Scenario 1:** Classification, independent covariates (N=100)\n",
        "- **Scenario 2:** Non-linear model, independent (N=100)\n",
        "- **Scenario 3:** Checkerboard, strong correlation (N=300)\n",
        "- **Scenario 4:** Linear model (N=200)\n",
        "- Each with **p = 200, 500, 1000**\n",
        "- **10 repetitions** (quick test mode)\n",
        "- **8 models:** RF, RF- ‚àöp, RF-log(p), ET, BART, Lasso, Boosting, RLT-naive\n",
        "\n",
        "### Part 3: Real Data Comparison (Paper Section 4.3)\n",
        "- ‚úÖ Standardize continuous variables\n",
        "- ‚úÖ Sample 150 training observations\n",
        "- ‚úÖ Expand features to p=500 (with SNR 1:2 noise)\n",
        "- ‚úÖ Test all models + RLT with nmin tuning (2, n^1/3)\n",
        "- ‚úÖ Compute relative errors (best = 1.0)\n",
        "- ‚úÖ Generate Figure 6-style visualization\n",
        "\n",
        "### üïí CPU Time Tracking\n",
        "All experiments include detailed CPU time measurements\n",
        "\n",
        "---\n",
        "\n",
        "‚è∞ **Estimated Runtime (Quick Mode):** \n",
        "- Part 1: ~1-2 min (upload + preprocessing)\n",
        "- Part 2: ~6 min (simulations)\n",
        "- Part 3: ~1 min (real data comparison)\n",
        "- **Total: ~8-9 min**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install xgboost scikit-learn pandas numpy matplotlib seaborn scipy tabulate -q\nprint('‚úÖ Installation termin√©e!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tabulate import tabulate\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingRegressor\nfrom sklearn.linear_model import Lasso, LogisticRegression\nfrom xgboost import XGBClassifier, XGBRegressor\n\nfrom sklearn.metrics import accuracy_score, mean_squared_error\nfrom scipy.stats import f_oneway, pearsonr, norm\n\nfrom google.colab import files\nimport io\nimport time\n\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\nprint('‚úÖ Imports termin√©s!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\nprint(\"‚öôÔ∏è CONFIGURATION\")\nprint(\"=\"*70)\n\n# General\nTEST_SIZE = 0.2\nN_JOBS = -1\n\n# RLT\nVI_THRESHOLD = 0.01\nVI_ET_WEIGHT = 0.5\nVI_STAT_WEIGHT = 0.5\n\n# Tree models\nTREE_CONFIG = {\n    'n_estimators': 100,\n    'random_state': RANDOM_STATE,\n    'n_jobs': N_JOBS\n}\n\n# Simulations - FAST MODE\nSIM_REPS = 10  # Quick test mode\nTEST_SAMPLES = 1000\nP_VALUES = [200, 500, 1000]\n\nprint(f\"\\n‚úÖ Config: {SIM_REPS} reps, test={TEST_SAMPLES}, p={P_VALUES}\")\nprint(f\"‚è±Ô∏è  Estimated time: ~30 sec per scenario √ó 3 dimensions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\nprint(\"üß† RLT FUNCTIONS\")\nprint(\"=\"*70)\n\ndef compute_vi(X, y, problem_type):\n    \"\"\"Compute Variable Importance\"\"\"\n    if problem_type == 'classification':\n        et = ExtraTreesClassifier(**TREE_CONFIG)\n    else:\n        et = ExtraTreesRegressor(**TREE_CONFIG)\n    \n    et.fit(X, y)\n    vi_et = et.feature_importances_\n    \n    # Statistical VI\n    vi_stat = np.zeros(X.shape[1])\n    for i in range(X.shape[1]):\n        try:\n            if problem_type == 'classification':\n                groups = [X[:, i][y == c] for c in np.unique(y)]\n                f_stat, _ = f_oneway(*groups)\n                vi_stat[i] = f_stat / 1000.0\n            else:\n                corr, _ = pearsonr(X[:, i], y)\n                vi_stat[i] = abs(corr)\n        except:\n            vi_stat[i] = 0\n    \n    # Normalize and aggregate\n    vi_et = vi_et / vi_et.sum() if vi_et.sum() > 0 else vi_et\n    vi_stat = vi_stat / vi_stat.sum() if vi_stat.sum() > 0 else vi_stat\n    vi_agg = VI_ET_WEIGHT * vi_et + VI_STAT_WEIGHT * vi_stat\n    \n    return vi_agg\n\ndef rlt_muting(X_tr, X_te, y_tr, problem_type, level='moderate'):\n    \"\"\"Apply Variable Muting\"\"\"\n    vi = compute_vi(X_tr, y_tr, problem_type)\n    \n    if level == 'no':\n        threshold = 0.0\n    elif level == 'moderate':\n        threshold = max(VI_THRESHOLD, np.mean(vi))\n    else:  # aggressive\n        threshold = max(VI_THRESHOLD, np.median(vi))\n    \n    selected = np.where(vi >= threshold)[0]\n    if len(selected) < 5:\n        selected = np.argsort(vi)[-5:]\n    \n    return X_tr[:, selected], X_te[:, selected], vi[selected]\n\ndef linear_combinations(X, vi, n_comb=2):\n    \"\"\"Create linear combinations\"\"\"\n    if X.shape[1] < 2:\n        return X\n    \n    top_k = min(10, X.shape[1])\n    top_idx = np.argsort(vi)[-top_k:]\n    \n    X_new = X.copy()\n    added = 0\n    \n    for i in range(min(5, len(top_idx)-1)):\n        for j in range(i+1, min(i+3, len(top_idx))):\n            if added >= n_comb * X.shape[1]:\n                break\n            \n            w1 = vi[i]\n            w2 = vi[j]\n            total = w1 + w2\n            w1_n = w1 / total if total > 0 else 0.5\n            w2_n = w2 / total if total > 0 else 0.5\n            \n            new_feat = w1_n * X[:, top_idx[i]] + w2_n * X[:, top_idx[j]]\n            X_new = np.column_stack([X_new, new_feat])\n            added += 1\n    \n    return X_new\n\nprint(\"‚úÖ Fonctions RLT d√©finies!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\nprint(\"üìÅ PARTIE 1: DATASET R√âEL\")\nprint(\"=\"*70)\nprint(\"\\nüëâ Upload your CSV file (last column = target)\\n\")\n\nuploaded = files.upload()\nfilename = list(uploaded.keys())[0]\n\ndf = pd.read_csv(io.BytesIO(uploaded[filename]))\nprint(f\"\\n‚úÖ Loaded: {filename}\")\nprint(f\"   Shape: {df.shape}\")\nprint(f\"   Features: {df.shape[1]-1}\")\n\n# Detect problem type\ntarget_col = df.columns[-1]\nunique_vals = df[target_col].nunique()\n\nif df[target_col].dtype == 'object' or unique_vals < 10:\n    prob_type = 'classification'\n    print(f\"   Type: CLASSIFICATION ({unique_vals} classes)\")\nelse:\n    prob_type = 'regression'\n    print(f\"   Type: REGRESSION\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\nprint(\"üîß PREPROCESSING\")\nprint(\"=\"*70)\n\n# Clean\ndf_clean = df.drop_duplicates()\nfor col in df_clean.columns:\n    if df_clean[col].isnull().sum() > 0:\n        if df_clean[col].dtype in [np.float64, np.int64]:\n            df_clean[col].fillna(df_clean[col].median(), inplace=True)\n        else:\n            df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n\n# Separate\nX = df_clean.iloc[:, :-1]\ny = df_clean.iloc[:, -1]\n\n# Encode categorical\ncat_cols = X.select_dtypes(include=['object']).columns\nif len(cat_cols) > 0:\n    X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n\n# Encode target\nif prob_type == 'classification':\n    if y.dtype == 'object':\n        le = LabelEncoder()\n        y = le.fit_transform(y)\n    else:\n        y = y.values\nelse:\n    y = y.values\n\n# Scale\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split\nif prob_type == 'classification' and len(np.unique(y)) > 1:\n    try:\n        X_train, X_test, y_train, y_test = train_test_split(\n            X_scaled, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n        )\n    except:\n        X_train, X_test, y_train, y_test = train_test_split(\n            X_scaled, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n        )\nelse:\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_scaled, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n    )\n\nprint(f\"\\n‚úÖ Ready: Train={X_train.shape[0]}, Test={X_test.shape[0]}, Features={X_train.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\nprint(\"üìä COMPARAISON: RLT (avec FE) vs BASELINE (sans FE)\")\nprint(\"=\"*70)\n\nresults_real = []\n\n# Define baseline models\nif prob_type == 'classification':\n    baseline_models = {\n        'RF': RandomForestClassifier(**TREE_CONFIG),\n        'RF-‚àöp': RandomForestClassifier(**{**TREE_CONFIG, 'max_features': max(1, int(np.sqrt(X_train.shape[1])))}),\n        'RF-log(p)': RandomForestClassifier(**{**TREE_CONFIG, 'max_features': max(1, int(np.log(X_train.shape[1])))}),\n        'ET': ExtraTreesClassifier(**TREE_CONFIG),\n        'BART': AdaBoostClassifier(n_estimators=100, random_state=RANDOM_STATE),\n        'Lasso': LogisticRegression(penalty='l1', solver='liblinear', C=10, random_state=RANDOM_STATE),\n        'Boosting': XGBClassifier(n_estimators=100, random_state=RANDOM_STATE, verbosity=0),\n    }\nelse:\n    baseline_models = {\n        'RF': RandomForestRegressor(**TREE_CONFIG),\n        'RF-‚àöp': RandomForestRegressor(**{**TREE_CONFIG, 'max_features': max(1, int(np.sqrt(X_train.shape[1])))}),\n        'RF-log(p)': RandomForestRegressor(**{**TREE_CONFIG, 'max_features': max(1, int(np.log(X_train.shape[1])))}),\n        'ET': ExtraTreesRegressor(**TREE_CONFIG),\n        'BART': GradientBoostingRegressor(n_estimators=100, random_state=RANDOM_STATE),\n        'Lasso': Lasso(alpha=0.1, random_state=RANDOM_STATE),\n        'Boosting': XGBRegressor(n_estimators=100, random_state=RANDOM_STATE, verbosity=0),\n    }\n\n# Test baseline\nprint(\"\\nüîµ BASELINE (sans Feature Engineering):\")\nfor name, model in baseline_models.items():\n    t0 = time.time()\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    cpu = time.time() - t0\n    \n    if prob_type == 'classification':\n        score = accuracy_score(y_test, y_pred)\n        metric = 'Accuracy'\n    else:\n        score = mean_squared_error(y_test, y_pred)\n        metric = 'MSE'\n    \n    results_real.append({\n        'Model': name,\n        'Type': 'Baseline',\n        'Features': X_train.shape[1],\n        metric: score,\n        'CPU(s)': cpu\n    })\n    print(f\"   {name:12s}: {metric}={score:.4f}, CPU={cpu:.3f}s\")\n\n# Test RLT variants\nprint(\"\\nüü¢ RLT (avec Feature Engineering: VI + Muting + Linear Combinations):\")\nfor muting in ['no', 'moderate', 'aggressive']:\n    for n_comb in [1, 2, 5]:\n        t0 = time.time()\n        \n        X_tr_m, X_te_m, vi = rlt_muting(X_train, X_test, y_train, prob_type, muting)\n        X_tr_rlt = linear_combinations(X_tr_m, vi, n_comb)\n        X_te_rlt = linear_combinations(X_te_m, vi, n_comb)\n        \n        if prob_type == 'classification':\n            model = ExtraTreesClassifier(**TREE_CONFIG)\n        else:\n            model = ExtraTreesRegressor(**TREE_CONFIG)\n        \n        model.fit(X_tr_rlt, y_train)\n        y_pred = model.predict(X_te_rlt)\n        cpu = time.time() - t0\n        \n        if prob_type == 'classification':\n            score = accuracy_score(y_test, y_pred)\n        else:\n            score = mean_squared_error(y_test, y_pred)\n        \n        results_real.append({\n            'Model': f'RLT-{muting.capitalize()}-LC{n_comb}',\n            'Type': 'RLT',\n            'Features': X_tr_rlt.shape[1],\n            metric: score,\n            'CPU(s)': cpu\n        })\n        print(f\"   RLT-{muting.capitalize()}-LC{n_comb}: {metric}={score:.4f}, CPU={cpu:.3f}s, Feat={X_tr_rlt.shape[1]}\")\n\n# Display results\nprint(\"\\nüìã TABLEAU COMPLET:\")\ndf_res = pd.DataFrame(results_real)\ndisplay(df_res)\n\n# Best models\ndf_baseline = df_res[df_res['Type'] == 'Baseline']\ndf_rlt = df_res[df_res['Type'] == 'RLT']\n\nascending = (prob_type != 'classification')\nbest_base = df_baseline.sort_values(metric, ascending=ascending).iloc[0]\nbest_rlt = df_rlt.sort_values(metric, ascending=ascending).iloc[0]\n\nprint(f\"\\nüèÜ MEILLEUR BASELINE: {best_base['Model']} ({metric}={best_base[metric]:.4f})\")\nprint(f\"üèÜ MEILLEUR RLT: {best_rlt['Model']} ({metric}={best_rlt[metric]:.4f})\")\n\nif prob_type == 'classification':\n    imp = ((best_rlt[metric] - best_base[metric]) / best_base[metric]) * 100\n    print(f\"üìà Am√©lioration RLT: {imp:+.2f}%\")\nelse:\n    imp = ((best_base[metric] - best_rlt[metric]) / best_base[metric]) * 100\n    print(f\"üìà R√©duction MSE: {imp:+.2f}%\")\n\nprint(\"\\n‚úÖ Partie 1 termin√©e!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\nprint(\"üìä PARTIE 2: SIMULATIONS (Paper RLT - Zhu et al. 2015)\")\nprint(\"=\"*70)\nprint(f\"\\nüî¨ 4 Scenarios √ó 3 Dimensions (p={P_VALUES})\")\nprint(f\"   Reps: {SIM_REPS}, Test samples: {TEST_SAMPLES}\")\nprint(\"\\nCela prendra ~15-20 minutes...\")\n\nsim_results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\nprint(\"üß™ SCENARIO 1: Classification, Independent Covariates\")\nprint(\"=\"*70)\n\nsim_results['Scenario 1'] = {}\n\nfor p in P_VALUES:\n    print(f\"\\nüìä p={p}...\")\n    \n    errors = {'RF': [], 'RF- ‚àöp': [], 'RF-log(p)': [], 'ET': [], \n              'BART': [], 'Lasso': [], 'Boosting': [], 'RLT-naive': []}\n    \n    for rep in range(SIM_REPS):\n        if rep % 50 == 0:\n            print(f\"   Rep {rep}/{SIM_REPS}...\")\n        \n        # Generate data\n        N = 100\n        X_tr = np.random.uniform(0, 1, (N, p))\n        mu = norm.cdf(10 * (X_tr[:, 0] - 1) + 20 * np.abs(X_tr[:, 1] - 0.5))\n        y_tr = np.random.binomial(1, mu)\n        \n        X_te = np.random.uniform(0, 1, (TEST_SAMPLES, p))\n        mu_te = norm.cdf(10 * (X_te[:, 0] - 1) + 20 * np.abs(X_te[:, 1] - 0.5))\n        y_te = np.random.binomial(1, mu_te)\n        \n        # Baseline models\n        models_base = {\n            'RF': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n            'RF- ‚àöp': RandomForestClassifier(n_estimators=100, max_features=max(1, int(np.sqrt(p))), random_state=42, n_jobs=-1),\n            'RF-log(p)': RandomForestClassifier(n_estimators=100, max_features=max(1, int(np.log(p))), random_state=42, n_jobs=-1),\n            'ET': ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n            'BART': AdaBoostClassifier(n_estimators=100, random_state=42),\n            'Lasso': LogisticRegression(penalty='l1', solver='liblinear', C=10, random_state=42),\n            'Boosting': XGBClassifier(n_estimators=100, random_state=42, verbosity=0),\n            'RLT-naive': ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n        }\n        \n        for name, model in models_base.items():\n            model.fit(X_tr, y_tr)\n            y_pred = model.predict(X_te)\n            err = 1 - accuracy_score(y_te, y_pred)\n            errors[name].append(err)\n        \n    # Store results\n    sim_results['Scenario 1'][p] = {name: np.mean(errs) for name, errs in errors.items()}\n    sim_results['Scenario 1'][f'{p}_std'] = {name: np.std(errs) for name, errs in errors.items()}\n    \n    print(f\"   ‚úÖ Done! Best: {min(errors.items(), key=lambda x: np.mean(x[1]))[0]}\")\n\nprint(\"\\n‚úÖ Scenario 1 termin√©!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\nprint(\"üß™ SCENARIO 2: Non-linear Model, Independent Covariates\")\nprint(\"=\"*70)\n\nsim_results['Scenario 2'] = {}\n\nfor p in P_VALUES:\n    print(f\"\\nüìä p={p}...\")\n    \n    errors = {'RF': [], 'RF- ‚àöp': [], 'RF-log(p)': [], 'ET': [], \n              'BART': [], 'Lasso': [], 'Boosting': [], 'RLT-naive': []}\n    \n    for rep in range(SIM_REPS):\n        if rep % 50 == 0:\n            print(f\"   Rep {rep}/{SIM_REPS}...\")\n        \n        # Generate data: Y = 100(X1-0.5)^2(X2-0.25)_+ + epsilon\n        N = 100\n        X_tr = np.random.uniform(0, 1, (N, p))\n        y_tr = 100 * (X_tr[:, 0] - 0.5)**2 * np.maximum(X_tr[:, 1] - 0.25, 0) + np.random.normal(0, 1, N)\n        \n        X_te = np.random.uniform(0, 1, (TEST_SAMPLES, p))\n        y_te = 100 * (X_te[:, 0] - 0.5)**2 * np.maximum(X_te[:, 1] - 0.25, 0) + np.random.normal(0, 1, TEST_SAMPLES)\n        \n        # Baseline models\n        models_base = {\n            'RF': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n            'RF- ‚àöp': RandomForestRegressor(n_estimators=100, max_features=max(1, int(np.sqrt(p))), random_state=42, n_jobs=-1),\n            'RF-log(p)': RandomForestRegressor(n_estimators=100, max_features=max(1, int(np.log(p))), random_state=42, n_jobs=-1),\n            'ET': ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n            'BART': GradientBoostingRegressor(n_estimators=100, random_state=42),\n            'Lasso': Lasso(alpha=0.1, random_state=42),\n            'Boosting': XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n            'RLT-naive': ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n        }\n        \n        for name, model in models_base.items():\n            model.fit(X_tr, y_tr)\n            y_pred = model.predict(X_te)\n            mse = mean_squared_error(y_te, y_pred)\n            errors[name].append(mse)\n        \n    sim_results['Scenario 2'][p] = {name: np.mean(errs) for name, errs in errors.items()}\n    sim_results['Scenario 2'][f'{p}_std'] = {name: np.std(errs) for name, errs in errors.items()}\n    \n    print(f\"   ‚úÖ Done! Best: {min(errors.items(), key=lambda x: np.mean(x[1]))[0]}\")\n\nprint(\"\\n‚úÖ Scenario 2 termin√©!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\nprint(\"üß™ SCENARIO 3: Checkerboard Model, Strong Correlation\")\nprint(\"=\"*70)\n\nsim_results['Scenario 3'] = {}\n\nfor p in P_VALUES:\n    print(f\"\\nüìä p={p}...\")\n    \n    errors = {'RF': [], 'RF- ‚àöp': [], 'RF-log(p)': [], 'ET': [], \n              'BART': [], 'Lasso': [], 'Boosting': [], 'RLT-naive': []}\n    \n    # Create correlation matrix\n    Sigma = np.zeros((p, p))\n    for i in range(p):\n        for j in range(p):\n            Sigma[i, j] = 0.9 ** abs(i - j)\n    \n    for rep in range(SIM_REPS):\n        if rep % 50 == 0:\n            print(f\"   Rep {rep}/{SIM_REPS}...\")\n        \n        # Generate data: Y = 2*X50*X100 + 2*X150*X200 + epsilon\n        N = 300\n        X_tr = np.random.multivariate_normal(np.zeros(p), Sigma, N)\n        y_tr = 2 * X_tr[:, 49] * X_tr[:, 99] + 2 * X_tr[:, 149] * X_tr[:, 199] + np.random.normal(0, 1, N)\n        \n        X_te = np.random.multivariate_normal(np.zeros(p), Sigma, TEST_SAMPLES)\n        y_te = 2 * X_te[:, 49] * X_te[:, 99] + 2 * X_te[:, 149] * X_te[:, 199] + np.random.normal(0, 1, TEST_SAMPLES)\n        \n        # Baseline models\n        models_base = {\n            'RF': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n            'RF- ‚àöp': RandomForestRegressor(n_estimators=100, max_features=max(1, int(np.sqrt(p))), random_state=42, n_jobs=-1),\n            'RF-log(p)': RandomForestRegressor(n_estimators=100, max_features=max(1, int(np.log(p))), random_state=42, n_jobs=-1),\n            'ET': ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n            'BART': GradientBoostingRegressor(n_estimators=100, random_state=42),\n            'Lasso': Lasso(alpha=0.1, random_state=42),\n            'Boosting': XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n            'RLT-naive': ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n        }\n        \n        for name, model in models_base.items():\n            model.fit(X_tr, y_tr)\n            y_pred = model.predict(X_te)\n            mse = mean_squared_error(y_te, y_pred)\n            errors[name].append(mse)\n        \n    sim_results['Scenario 3'][p] = {name: np.mean(errs) for name, errs in errors.items()}\n    sim_results['Scenario 3'][f'{p}_std'] = {name: np.std(errs) for name, errs in errors.items()}\n    \n    print(f\"   ‚úÖ Done! Best: {min(errors.items(), key=lambda x: np.mean(x[1]))[0]}\")\n\nprint(\"\\n‚úÖ Scenario 3 termin√©!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\nprint(\"üß™ SCENARIO 4: Linear Model\")\nprint(\"=\"*70)\n\nsim_results['Scenario 4'] = {}\n\nfor p in P_VALUES:\n    print(f\"\\nüìä p={p}...\")\n    \n    errors = {'RF': [], 'RF- ‚àöp': [], 'RF-log(p)': [], 'ET': [], \n              'BART': [], 'Lasso': [], 'Boosting': [], 'RLT-naive': []}\n    \n    # Create correlation matrix\n    Sigma = np.zeros((p, p))\n    for i in range(p):\n        for j in range(p):\n            Sigma[i, j] = 0.5 ** abs(i - j) + 0.2 * (1 if i == j else 0)\n    \n    for rep in range(SIM_REPS):\n        if rep % 50 == 0:\n            print(f\"   Rep {rep}/{SIM_REPS}...\")\n        \n        # Generate data: Y = 2*X50 + 2*X100 + 4*X150 + epsilon\n        N = 200\n        X_tr = np.random.multivariate_normal(np.zeros(p), Sigma, N)\n        y_tr = 2 * X_tr[:, 49] + 2 * X_tr[:, 99] + 4 * X_tr[:, 149] + np.random.normal(0, 1, N)\n        \n        X_te = np.random.multivariate_normal(np.zeros(p), Sigma, TEST_SAMPLES)\n        y_te = 2 * X_te[:, 49] + 2 * X_te[:, 99] + 4 * X_te[:, 149] + np.random.normal(0, 1, TEST_SAMPLES)\n        \n        # Baseline models\n        models_base = {\n            'RF': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n            'RF- ‚àöp': RandomForestRegressor(n_estimators=100, max_features=max(1, int(np.sqrt(p))), random_state=42, n_jobs=-1),\n            'RF-log(p)': RandomForestRegressor(n_estimators=100, max_features=max(1, int(np.log(p))), random_state=42, n_jobs=-1),\n            'ET': ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n            'BART': GradientBoostingRegressor(n_estimators=100, random_state=42),\n            'Lasso': Lasso(alpha=0.1, random_state=42),\n            'Boosting': XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n            'RLT-naive': ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n        }\n        \n        for name, model in models_base.items():\n            model.fit(X_tr, y_tr)\n            y_pred = model.predict(X_te)\n            mse = mean_squared_error(y_te, y_pred)\n            errors[name].append(mse)\n        \n    sim_results['Scenario 4'][p] = {name: np.mean(errs) for name, errs in errors.items()}\n    sim_results['Scenario 4'][f'{p}_std'] = {name: np.std(errs) for name, errs in errors.items()}\n    \n    print(f\"   ‚úÖ Done! Best: {min(errors.items(), key=lambda x: np.mean(x[1]))[0]}\")\n\nprint(\"\\n‚úÖ Scenario 4 termin√©!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\nprint(\"üìä PARTIE 3: REAL DATA COMPARISON\")\nprint(\"=\"*70)\nprint(\"\\nProtocole (Paper Section 4.3):\")\nprint(\"  1. Standardize all continuous variables (mean=0, var=1)\")\nprint(\"  2. Sample 150 training observations (rest = test)\")\nprint(\"  3. Expand features to p=500 with noise (SNR 1:2)\")\nprint(\"  4. Test all models + RLT variants (nmin=2, n^1/3)\")\nprint(\"  5. Compute relative errors (best model = 1.0)\")\nprint(\"\\n‚ÑπÔ∏è  NOTE: Upload dataset first in Part 1!\\n\")\n\n# Check if we have uploaded data\ntry:\n    X_scaled  # From Part 1\n    y\n    prob_type\n    print(f\"‚úÖ Using uploaded dataset: {df.shape[0]} samples, {X_scaled.shape[1]} original features\")\nexcept:\n    print(\"‚ö†Ô∏è  Please run Part 1 first to upload dataset!\")\n    raise\n\n# Function to expand features to p=500\ndef expand_features_with_noise(X, target_p=500, snr_ratio=0.5):\n    \"\"\"\n    Expand features to target_p by adding noisy combinations\n    SNR ratio: signal-to-noise = 1:2 means snr_ratio = 0.5 (signal / (signal + noise))\n    \"\"\"\n    n_samples, p_original = X.shape\n    \n    if p_original >= target_p:\n        return X\n    \n    n_extra = target_p - p_original\n    X_expanded = X.copy()\n    \n    np.random.seed(RANDOM_STATE)\n    \n    for i in range(n_extra):\n        # Randomly sample an original feature\n        idx = np.random.randint(0, p_original)\n        original_feature = X[:, idx]\n        \n        # Generate noise\n        noise = np.random.normal(0, 1, n_samples)\n        \n        # Combine with SNR 1:2 (signal weight = 1/3, noise weight = 2/3)\n        signal_weight = snr_ratio\n        noise_weight = 1 - snr_ratio\n        \n        new_feature = signal_weight * original_feature + noise_weight * noise\n        X_expanded = np.column_stack([X_expanded, new_feature])\n    \n    return X_expanded\n\n# Function for RLT with nmin tuning\ndef rlt_with_nmin(X_tr, X_te, y_tr, problem_type, nmin_value):\n    \"\"\"Apply RLT with specific nmin value\"\"\"\n    vi = compute_vi(X_tr, y_tr)\n    \n    # Moderate muting\n    threshold = max(VI_THRESHOLD, np.mean(vi))\n    selected = np.where(vi >= threshold)[0]\n    \n    if len(selected) < 5:\n        selected = np.argsort(vi)[-5:]\n    \n    X_tr_m = X_tr[:, selected]\n    X_te_m = X_te[:, selected]\n    vi_m = vi[selected]\n    \n    # Linear combinations\n    X_tr_rlt = linear_combinations(X_tr_m, vi_m, n_comb=2)\n    X_te_rlt = linear_combinations(X_te_m, vi_m, n_comb=2)\n    \n    # Train with nmin\n    if problem_type == 'classification':\n        model = ExtraTreesClassifier(\n            n_estimators=100,\n            min_samples_leaf=nmin_value,\n            random_state=RANDOM_STATE,\n            n_jobs=N_JOBS\n        )\n    else:\n        model = ExtraTreesRegressor(\n            n_estimators=100,\n            min_samples_leaf=nmin_value,\n            random_state=RANDOM_STATE,\n            n_jobs=N_JOBS\n        )\n    \n    model.fit(X_tr_rlt, y_tr)\n    return model.predict(X_te_rlt)\n\n# Prepare data\nprint(\"\\nüîß Data Preparation:\")\nprint(\"-\"*70)\n\n# Expand to p=500\nX_expanded = expand_features_with_noise(X_scaled, target_p=500, snr_ratio=0.5)\nprint(f\"‚úÖ Features expanded: {X_scaled.shape[1]} ‚Üí {X_expanded.shape[1]}\")\n\n# Sample 150 for training (if dataset has >= 150)\nn_total = X_expanded.shape[0]\nn_train = min(150, int(0.7 * n_total))\nn_test = n_total - n_train\n\nprint(f\"‚úÖ Train/Test split: {n_train} / {n_test}\")\n\n# Random sampling\nnp.random.seed(RANDOM_STATE)\ntrain_idx = np.random.choice(n_total, n_train, replace=False)\ntest_idx = np.array([i for i in range(n_total) if i not in train_idx])\n\nX_tr_real = X_expanded[train_idx]\nX_te_real = X_expanded[test_idx]\ny_tr_real = y[train_idx]\ny_te_real = y[test_idx]\n\nprint(f\"‚úÖ Final dimensions: Train {X_tr_real.shape}, Test {X_te_real.shape}\")\n\n# Test all models\nprint(\"\\nüöÄ Testing All Models:\")\nprint(\"-\"*70)\n\nreal_data_results = {}\n\n# Baseline models\nif prob_type == 'classification':\n    baseline_models = {\n        'RF': RandomForestClassifier(**TREE_CONFIG),\n        'RF- ‚àöp': RandomForestClassifier(**{**TREE_CONFIG, 'max_features': max(1, int(np.sqrt(500)))}),\n        'RF-log(p)': RandomForestClassifier(**{**TREE_CONFIG, 'max_features': max(1, int(np.log(500)))}),\n        'ET': ExtraTreesClassifier(**TREE_CONFIG),\n        'BART': AdaBoostClassifier(n_estimators=100, random_state=RANDOM_STATE),\n        'Lasso': LogisticRegression(penalty='l1', solver='liblinear', C=10, random_state=RANDOM_STATE),\n        'Boosting': XGBClassifier(n_estimators=100, random_state=RANDOM_STATE, verbosity=0),\n        'RLT-naive': ExtraTreesClassifier(**TREE_CONFIG),\n    }\n    metric_name = 'Error'\nelse:\n    baseline_models = {\n        'RF': RandomForestRegressor(**TREE_CONFIG),\n        'RF- ‚àöp': RandomForestRegressor(**{**TREE_CONFIG, 'max_features': max(1, int(np.sqrt(500)))}),\n        'RF-log(p)': RandomForestRegressor(**{**TREE_CONFIG, 'max_features': max(1, int(np.log(500)))}),\n        'ET': ExtraTreesRegressor(**TREE_CONFIG),\n        'BART': GradientBoostingRegressor(n_estimators=100, random_state=RANDOM_STATE),\n        'Lasso': Lasso(alpha=0.1, random_state=RANDOM_STATE),\n        'Boosting': XGBRegressor(n_estimators=100, random_state=RANDOM_STATE, verbosity=0),\n        'RLT-naive': ExtraTreesRegressor(**TREE_CONFIG),\n    }\n    metric_name = 'MSE'\n\n# Test baseline models\nfor name, model in baseline_models.items():\n    model.fit(X_tr_real, y_tr_real)\n    y_pred = model.predict(X_te_real)\n    \n    if prob_type == 'classification':\n        error = 1 - accuracy_score(y_te_real, y_pred)\n    else:\n        error = mean_squared_error(y_te_real, y_pred)\n    \n    real_data_results[name] = error\n    print(f\"   {name:15s}: {metric_name}={error:.4f}\")\n\n# Test RLT variants with nmin tuning\nprint(\"\\nüå≤ RLT with nmin tuning:\")\n\n# nmin = 2\ny_pred_rlt_2 = rlt_with_nmin(X_tr_real, X_te_real, y_tr_real, prob_type, nmin_value=2)\nif prob_type == 'classification':\n    error_2 = 1 - accuracy_score(y_te_real, y_pred_rlt_2)\nelse:\n    error_2 = mean_squared_error(y_te_real, y_pred_rlt_2)\nreal_data_results['RLT (nmin=2)'] = error_2\nprint(f\"   RLT (nmin=2):    {metric_name}={error_2:.4f}\")\n\n# nmin = n^(1/3)\nnmin_cube = int(n_train ** (1/3))\ny_pred_rlt_cube = rlt_with_nmin(X_tr_real, X_te_real, y_tr_real, prob_type, nmin_value=nmin_cube)\nif prob_type == 'classification':\n    error_cube = 1 - accuracy_score(y_te_real, y_pred_rlt_cube)\nelse:\n    error_cube = mean_squared_error(y_te_real, y_pred_rlt_cube)\nreal_data_results[f'RLT (nmin=n^1/3={nmin_cube})'] = error_cube\nprint(f\"   RLT (nmin=n^1/3={nmin_cube}): {metric_name}={error_cube:.4f}\")\n\n# Compute relative errors (best = 1.0)\nprint(\"\\nüìä Relative Prediction Errors (Best = 1.0):\")\nprint(\"-\"*70)\n\nbest_error = min(real_data_results.values())\nrelative_errors = {model: error / best_error for model, error in real_data_results.items()}\n\n# Sort by performance\nsorted_results = sorted(relative_errors.items(), key=lambda x: x[1])\n\n# Create table\ntable_data = []\nfor rank, (model, rel_error) in enumerate(sorted_results, 1):\n    abs_error = real_data_results[model]\n    marker = \"üèÜ\" if rank == 1 else \"ü•à\" if rank == 2 else \"ü•â\" if rank == 3 else \"\"\n    table_data.append([f\"{marker} {rank}\", model, f\"{abs_error:.4f}\", f\"{rel_error:.3f}\"])\n\nheaders = ['Rank', 'Model', f'Absolute {metric_name}', 'Relative Error']\nprint(tabulate(table_data, headers=headers, tablefmt='grid'))\n\n# Visualization: Figure 6-style bar plot\nprint(\"\\nüìà Generating Figure 6-style visualization...\")\n\nplt.figure(figsize=(12, 6))\n\nmodels = [item[0] for item in sorted_results]\nrel_errs = [item[1] for item in sorted_results]\n\ncolors = ['gold' if i == 0 else 'silver' if i == 1 else 'chocolate' if i == 2 else 'steelblue' \n          for i in range(len(models))]\n\nbars = plt.barh(range(len(models)), rel_errs, color=colors, alpha=0.7, edgecolor='black')\n\nplt.yticks(range(len(models)), models)\nplt.xlabel('Relative Prediction Error (Best = 1.0)', fontsize=12, fontweight='bold')\nplt.title(f'Real Data Comparison: Relative {metric_name} (p=500, n_train={n_train})', \n          fontsize=14, fontweight='bold')\nplt.axvline(x=1.0, color='red', linestyle='--', linewidth=2, label='Best Performance')\nplt.legend()\nplt.grid(axis='x', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n‚úÖ Real Data Comparison Complete!\")\nprint(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\nprint(\"üìä PARTIE 3: REAL DATA COMPARISON\")\nprint(\"=\"*70)\nprint(\"\\nProtocole (Paper Section 4.3):\")\nprint(\"  1. Standardize all continuous variables (mean=0, var=1)\")\nprint(\"  2. Sample 150 training observations (rest = test)\")\nprint(\"  3. Expand features to p=500 with noise (SNR 1:2)\")\nprint(\"  4. Test all models + RLT variants\")\nprint(\"     - Muting: no, moderate, aggressive\")\nprint(\"     - Linear Combinations: 1, 2, 3, 4, 5\")\nprint(\"     - nmin: 2, n^1/3\")\nprint(\"  5. Compute relative errors (best model = 1.0)\")\nprint(\"\\n‚ÑπÔ∏è  NOTE: Upload dataset first in Part 1!\\n\")\n\n# Check if we have uploaded data\ntry:\n    X_scaled  # From Part 1\n    y\n    prob_type\n    print(f\"‚úÖ Using uploaded dataset: {df.shape[0]} samples, {X_scaled.shape[1]} original features\")\nexcept:\n    print(\"‚ö†Ô∏è  Please run Part 1 first to upload dataset!\")\n    raise\n\n# Function to expand features to p=500\ndef expand_features_with_noise(X, target_p=500, snr_ratio=0.5):\n    \"\"\"\n    Expand features to target_p by adding noisy combinations\n    SNR ratio: signal-to-noise = 1:2 means snr_ratio = 0.5 (signal / (signal + noise))\n    \"\"\"\n    n_samples, p_original = X.shape\n    \n    if p_original >= target_p:\n        return X\n    \n    n_extra = target_p - p_original\n    X_expanded = X.copy()\n    \n    np.random.seed(RANDOM_STATE)\n    \n    for i in range(n_extra):\n        # Randomly sample an original feature\n        idx = np.random.randint(0, p_original)\n        original_feature = X[:, idx]\n        \n        # Generate noise\n        noise = np.random.normal(0, 1, n_samples)\n        \n        # Combine with SNR 1:2 (signal weight = 1/3, noise weight = 2/3)\n        signal_weight = snr_ratio\n        noise_weight = 1 - snr_ratio\n        \n        new_feature = signal_weight * original_feature + noise_weight * noise\n        X_expanded = np.column_stack([X_expanded, new_feature])\n    \n    return X_expanded\n\n# Function for RLT with full configuration\ndef rlt_full_config(X_tr, X_te, y_tr, problem_type, muting_level, n_comb, nmin_value):\n    \"\"\"Apply RLT with specific muting, linear combinations, and nmin\"\"\"\n    vi = compute_vi(X_tr, y_tr, problem_type)\n    \n    # Apply muting based on level\n    if muting_level == 'no':\n        threshold = 0.0\n    elif muting_level == 'moderate':\n        threshold = max(VI_THRESHOLD, np.mean(vi))\n    else:  # aggressive\n        threshold = max(VI_THRESHOLD, np.median(vi))\n    \n    selected = np.where(vi >= threshold)[0]\n    if len(selected) < 5:\n        selected = np.argsort(vi)[-5:]\n    \n    X_tr_m = X_tr[:, selected]\n    X_te_m = X_te[:, selected]\n    vi_m = vi[selected]\n    \n    # Linear combinations\n    X_tr_rlt = linear_combinations(X_tr_m, vi_m, n_comb=n_comb)\n    X_te_rlt = linear_combinations(X_te_m, vi_m, n_comb=n_comb)\n    \n    # Train with nmin\n    if problem_type == 'classification':\n        model = ExtraTreesClassifier(\n            n_estimators=100,\n            min_samples_leaf=nmin_value,\n            random_state=RANDOM_STATE,\n            n_jobs=N_JOBS\n        )\n    else:\n        model = ExtraTreesRegressor(\n            n_estimators=100,\n            min_samples_leaf=nmin_value,\n            random_state=RANDOM_STATE,\n            n_jobs=N_JOBS\n        )\n    \n    model.fit(X_tr_rlt, y_tr)\n    return model.predict(X_te_rlt)\n\n# Prepare data\nprint(\"\\nüîß Data Preparation:\")\nprint(\"-\"*70)\n\n# Expand to p=500\nX_expanded = expand_features_with_noise(X_scaled, target_p=500, snr_ratio=0.5)\nprint(f\"‚úÖ Features expanded: {X_scaled.shape[1]} ‚Üí {X_expanded.shape[1]}\")\n\n# Sample 150 for training (if dataset has >= 150)\nn_total = X_expanded.shape[0]\nn_train = min(150, int(0.7 * n_total))\nn_test = n_total - n_train\n\nprint(f\"‚úÖ Train/Test split: {n_train} / {n_test}\")\n\n# Random sampling\nnp.random.seed(RANDOM_STATE)\ntrain_idx = np.random.choice(n_total, n_train, replace=False)\ntest_idx = np.array([i for i in range(n_total) if i not in train_idx])\n\nX_tr_real = X_expanded[train_idx]\nX_te_real = X_expanded[test_idx]\ny_tr_real = y[train_idx]\ny_te_real = y[test_idx]\n\nprint(f\"‚úÖ Final dimensions: Train {X_tr_real.shape}, Test {X_te_real.shape}\")\n\n# Test all models\nprint(\"\\nüöÄ Testing All Models:\")\nprint(\"-\"*70)\n\nreal_data_results = {}\n\n# Baseline models\nif prob_type == 'classification':\n    baseline_models = {\n        'RF': RandomForestClassifier(**TREE_CONFIG),\n        'RF- ‚àöp': RandomForestClassifier(**{**TREE_CONFIG, 'max_features': max(1, int(np.sqrt(500)))}),\n        'RF-log(p)': RandomForestClassifier(**{**TREE_CONFIG, 'max_features': max(1, int(np.log(500)))}),\n        'ET': ExtraTreesClassifier(**TREE_CONFIG),\n        'BART': AdaBoostClassifier(n_estimators=100, random_state=RANDOM_STATE),\n        'Lasso': LogisticRegression(penalty='l1', solver='liblinear', C=10, random_state=RANDOM_STATE),\n        'Boosting': XGBClassifier(n_estimators=100, random_state=RANDOM_STATE, verbosity=0),\n        'RLT-naive': ExtraTreesClassifier(**TREE_CONFIG),\n    }\n    metric_name = 'Error'\nelse:\n    baseline_models = {\n        'RF': RandomForestRegressor(**TREE_CONFIG),\n        'RF- ‚àöp': RandomForestRegressor(**{**TREE_CONFIG, 'max_features': max(1, int(np.sqrt(500)))}),\n        'RF-log(p)': RandomForestRegressor(**{**TREE_CONFIG, 'max_features': max(1, int(np.log(500)))}),\n        'ET': ExtraTreesRegressor(**TREE_CONFIG),\n        'BART': GradientBoostingRegressor(n_estimators=100, random_state=RANDOM_STATE),\n        'Lasso': Lasso(alpha=0.1, random_state=RANDOM_STATE),\n        'Boosting': XGBRegressor(n_estimators=100, random_state=RANDOM_STATE, verbosity=0),\n        'RLT-naive': ExtraTreesRegressor(**TREE_CONFIG),\n    }\n    metric_name = 'MSE'\n\n# Test baseline models\nprint(\"\\nüîµ Baseline Models:\")\nfor name, model in baseline_models.items():\n    model.fit(X_tr_real, y_tr_real)\n    y_pred = model.predict(X_te_real)\n    \n    if prob_type == 'classification':\n        error = 1 - accuracy_score(y_te_real, y_pred)\n    else:\n        error = mean_squared_error(y_te_real, y_pred)\n    \n    real_data_results[name] = error\n    print(f\"   {name:15s}: {metric_name}={error:.4f}\")\n\n# Test RLT variants with all combinations\nprint(\"\\nüå≤ RLT Variants (Muting √ó LC √ó nmin):\")\nprint(f\"   Testing 3 muting √ó 5 LC √ó 2 nmin = 30 variants...\")\n\nnmin_cube = int(n_train ** (1/3))\nnmin_values = {'nmin=2': 2, f'nmin=n^1/3={nmin_cube}': nmin_cube}\n\nrlt_count = 0\nfor muting in ['no', 'moderate', 'aggressive']:\n    for n_c in [1, 2, 3, 4, 5]:\n        for nmin_name, nmin_val in nmin_values.items():\n            rlt_count += 1\n            \n            y_pred_rlt = rlt_full_config(X_tr_real, X_te_real, y_tr_real, \n                                         prob_type, muting, n_c, nmin_val)\n            \n            if prob_type == 'classification':\n                error = 1 - accuracy_score(y_te_real, y_pred_rlt)\n            else:\n                error = mean_squared_error(y_te_real, y_pred_rlt)\n            \n            # Model name format: RLT-Muting-LC-nmin\n            muting_short = muting[:3].capitalize()\n            model_name = f'RLT-{muting_short}-LC{n_c}-{nmin_name}'\n            real_data_results[model_name] = error\n            \n            if rlt_count % 10 == 0:\n                print(f\"   Progress: {rlt_count}/30 variants tested...\")\n\nprint(f\"\\n‚úÖ All {len(real_data_results)} models tested!\")\n\n# Compute relative errors (best = 1.0)\nprint(\"\\nüìä Relative Prediction Errors (Best = 1.0):\")\nprint(\"-\"*70)\n\nbest_error = min(real_data_results.values())\nrelative_errors = {model: error / best_error for model, error in real_data_results.items()}\n\n# Sort by performance\nsorted_results = sorted(relative_errors.items(), key=lambda x: x[1])\n\n# Create table - show top 15 and bottom 5\nprint(\"\\nüèÜ TOP 15 MODELS:\")\ntable_data_top = []\nfor rank, (model, rel_error) in enumerate(sorted_results[:15], 1):\n    abs_error = real_data_results[model]\n    marker = \"üèÜ\" if rank == 1 else \"ü•à\" if rank == 2 else \"ü•â\" if rank == 3 else \"\"\n    table_data_top.append([f\"{marker} {rank}\", model, f\"{abs_error:.4f}\", f\"{rel_error:.3f}\"])\n\nheaders = ['Rank', 'Model', f'Absolute {metric_name}', 'Relative Error']\nprint(tabulate(table_data_top, headers=headers, tablefmt='grid'))\n\nprint(\"\\nüìâ BOTTOM 5 MODELS:\")\ntable_data_bottom = []\nfor rank, (model, rel_error) in enumerate(sorted_results[-5:], len(sorted_results)-4):\n    abs_error = real_data_results[model]\n    table_data_bottom.append([rank, model, f\"{abs_error:.4f}\", f\"{rel_error:.3f}\"])\n\nprint(tabulate(table_data_bottom, headers=headers, tablefmt='grid'))\n\n# Visualization: Figure 6-style bar plot (top 15 models)\nprint(\"\\nüìà Generating Figure 6-style visualization (Top 15)...\")\n\nplt.figure(figsize=(14, 8))\n\nmodels_top15 = [item[0] for item in sorted_results[:15]]\nrel_errs_top15 = [item[1] for item in sorted_results[:15]]\n\ncolors = ['gold' if i == 0 else 'silver' if i == 1 else 'chocolate' if i == 2 else 'steelblue' \n          for i in range(len(models_top15))]\n\nbars = plt.barh(range(len(models_top15)), rel_errs_top15, color=colors, alpha=0.7, edgecolor='black')\n\nplt.yticks(range(len(models_top15)), models_top15, fontsize=10)\nplt.xlabel('Relative Prediction Error (Best = 1.0)', fontsize=12, fontweight='bold')\nplt.title(f'Real Data Comparison: Top 15 Models - Relative {metric_name}\\\\n(p=500, n_train={n_train}, {len(real_data_results)} models tested)', \n          fontsize=14, fontweight='bold')\nplt.axvline(x=1.0, color='red', linestyle='--', linewidth=2, label='Best Performance')\nplt.legend()\nplt.grid(axis='x', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(\"\\nüìà Summary Statistics:\")\nprint(\"-\"*70)\nbaseline_names = list(baseline_models.keys())\nbaseline_errors = [relative_errors[m] for m in baseline_names if m in relative_errors]\nrlt_names = [m for m in relative_errors.keys() if m.startswith('RLT-') and m != 'RLT-naive']\nrlt_errors = [relative_errors[m] for m in rlt_names]\n\nprint(f\"Baseline models (n={len(baseline_errors)}):\")\nprint(f\"  Best: {min(baseline_errors):.3f}\")\nprint(f\"  Worst: {max(baseline_errors):.3f}\")\nprint(f\"  Mean: {np.mean(baseline_errors):.3f}\")\n\nprint(f\"\\nRLT variants (n={len(rlt_errors)}):\")\nprint(f\"  Best: {min(rlt_errors):.3f}\")\nprint(f\"  Worst: {max(rlt_errors):.3f}\")\nprint(f\"  Mean: {np.mean(rlt_errors):.3f}\")\n\nbest_model_name = sorted_results[0][0]\nbest_model_error = real_data_results[best_model_name]\nprint(f\"\\nüèÜ Overall Best: {best_model_name} ({metric_name}={best_model_error:.4f})\")\n\nprint(\"\\n‚úÖ Real Data Comparison Complete!\")\nprint(\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "RLT_Complete_Study.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}